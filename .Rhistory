load("~/Documents/Bid-ask-dissertacao/ardia2024-CS2012-R/Bid-ask spread Ardia 2024 vs CS 2012.qmd")
setwd("~/Documents/Bid-ask-dissertacao/")
setwd("~/Documents/Bid-ask-dissertacao/ardia2024-CS2012-R/")
renv::activate()
install.packages("tidyverse")
install.packages("quantmod")
install.packages("bidask")
install.packages("purrr")
install.packages("readr")
renv::snapshot()
library(tidyverse)
library(quantmod)
library(bidask)
library(readr)
library(purrr)
company_codes <- read_csv("company_codes.csv")
# Baixando precos com Quantmod
getSymbols(company_codes$Company_Code, from = "2018-01-01", to = "2024-10-30", src = "yahoo")
# Calculando spread com Ardia e CS
bidask::spread(SBSP3.SA[,1:4], method = "EDGE", width = 21, na.rm = TRUE)
# Importar códigos de empresas
company_codes <- read_csv("company_codes.csv")
# Função segura para baixar dados
safe_getSymbols <- safely(function(symbol) {
getSymbols(symbol, src = "yahoo", from = "2017-01-01", to = "2024-10-30", auto.assign = FALSE)
})
# Aplicar a função a todos os códigos de empresas usando purrr::map
company_data_list <- company_codes$Company_Code %>%
map(~ safe_getSymbols(.x))
# Extrair os resultados bem-sucedidos e Nomear a lista com os códigos das empresas
company_data_clean <- company_data_list %>%
map("result") %>%
set_names(company_codes$Company_Code)
# Verificar quais downloads falharam
errors <- company_data_list %>%
map("error") %>%
keep(~ !is.null(.x))
if (length(errors) > 0) {
print("Alguns downloads falharam:")
print(errors)
} else {
print("Todos os dados foram baixados com sucesso.")
}
View(company_data_list)
company_data_list[[1]]%>%View()
.[["result"]]%>%View()
company_data_list[[1]].[["result"]]%>%View()
company_data_list[["result"]]%>%View()
company_data_list[[1]][["result"]]%>%View()
View(company_data_clean)
company_data_clean[["AESB3.SA"]]%>%View()
company_data_list[[1]][["result"]]%>%View()
company_data_clean[["AESB3.SA"]]%>%View()
# Agrupar as empresas com maiores médias de volume diários e selecionar os 30% maiores e 30% menores
# Calcular a média de volume para cada empresa
company_volumes <- company_data_clean %>%
# Extrair a coluna de Volume (coluna 5) de cada dataframe
map_dbl(~ mean(.x[[5]], na.rm = TRUE))
# Converter os resultados para um dataframe para melhor manipulação
company_volumes <- tibble(
Company = names(company_data_clean),
Mean_Volume = company_volumes
)
# Definir os percentis de 30% e 70%
volume_30 <- quantile(company_volumes$Mean_Volume, 0.3, na.rm = TRUE)
volume_70 <- quantile(company_volumes$Mean_Volume, 0.7, na.rm = TRUE)
# Atribuir cada empresa a um grupo com base na média de volume
company_volumes <- company_volumes %>%
mutate(
Group = case_when(
Mean_Volume <= volume_30 ~ "Low Volume (Bottom 30%)",
Mean_Volume > volume_70 ~ "High Volume (Top 30%)",
TRUE ~ "Middle Volume (40%)"
)
)
# Empresas de baixo volume (Bottom 30%)
low_volume <- company_volumes %>%
filter(Group == "Low Volume (Bottom 30%)") %>%
pull(Company)
# Empresas de alto volume (Top 30%)
high_volume <- company_volumes %>%
filter(Group == "High Volume (Top 30%)") %>%
pull(Company)
# Criando um company_data_clean_high_volume e company_data_clean_low_volume
company_data_clean_high_volume <- company_data_clean[high_volume]
company_data_clean_low_volume <- company_data_clean[low_volume]
View(company_data_clean_high_volume)
company_data_clean_high_volume[["ALOS3.SA"]]%>%View()
# Calcular os spreads para cada empresa
company_spreads_EDGE <- company_data_clean %>%
map(~ bidask::spread(.x[, 1:4], method = "EDGE", width = 21, na.rm = TRUE))
# Calcular o spread com method "CS" para cada empresa em company_spreads
company_spreads_CS <- company_data_clean %>%
map(~ bidask::spread(.x[, 1:4], method = "CS", width = 21, na.rm = TRUE))
# Juntar company_spreads e company_spreads_CS no mesmo dataframe com colunas de Data, Código, Spread_EDGE e Spread_CS
company_spreads_df <- map2_dfr(company_spreads_EDGE, company_spreads_CS, ~ {
data_frame(
Date = index(.x),
Spread_EDGE = .x,
Spread_CS = .y
)
}, .id = "Company_Code")
# Calcular os spreads médios para cada ano em cada método e aplicar na variável company_spreads_year
company_spreads_year <- company_spreads_df %>%
mutate(Year = year(Date)) %>%
group_by(Company_Code, Year) %>%
summarise(
Spread_EDGE = mean(Spread_EDGE, na.rm = TRUE),
Spread_CS = mean(Spread_CS, na.rm = TRUE)
)
# Filtrar o company_spread_df para high_volume e low_volume
company_spreads_high_volume <- company_spreads_year %>%
filter(Company_Code %in% high_volume)
company_spreads_low_volume <- company_spreads_year %>%
filter(Company_Code %in% low_volume)
# Filtrar o company_spread_year para os anos de 2017 a 2019 (antes da pandemia), para 2020 e 2021 (durante a pandemia) e para 2022 a 2024 (após a pandemia)
company_spreads_pre <- company_spreads_year %>%
filter(Year %in% 2017:2019)
company_spreads_dur <- company_spreads_year %>%
filter(Year %in% 2020:2021)
company_spreads_pos <- company_spreads_year %>%
filter(Year %in% 2022:2024)
View(company_spreads_dur)
View(company_spreads_df)
View(company_spreads_year)
library(tidyverse)
library(quantmod)
library(bidask)
library(readr)
library(purrr)
library(gt)
library(writexl)
# Importar códigos de empresas novamente
company_codes <- read_csv("company_codes.csv")
# Função para ler dados de arquivos CSV
read_company_data <- function(symbol) {
file_path <- paste0("prices-companies/", symbol, ".csv")
if (file.exists(file_path)) {
read_csv(file_path)
} else {
message("Arquivo não encontrado para: ", symbol)
NULL
}
}
# Aplicar a função a todos os códigos de empresas usando purrr::map
company_data_list <- company_codes$Company_Code %>%
map(~ read_company_data(.x))
# Função para remover linhas com valores NA de um dataframe
remove_na_rows <- function(df) {
df %>% drop_na()
}
# Filtrar elementos NULL e remover linhas com valores NA
company_data_clean <- company_data_list %>%
keep(~ !is.null(.x)) %>%
map(~ remove_na_rows(.x)) %>%
set_names(company_codes$Company_Code[!map_lgl(company_data_list, is.null)])
# Verificar quais downloads falharam
errors <- company_data_list %>%
map("error") %>%
keep(~ !is.null(.x))
if (length(errors) > 0) {
print("Alguns downloads falharam:")
print(errors)
} else {
print("Todos os dados foram baixados com sucesso.")
}
# Agrupar as empresas com maiores médias de volume diários e selecionar os 30% maiores e 30% menores
# Calcular a média de volume para cada empresa
company_volumes <- company_data_clean %>%
# Extrair a coluna de Volume (coluna 5) de cada dataframe
map_dbl(~ mean(.x[[5]], na.rm = TRUE))
# Converter os resultados para um dataframe para melhor manipulação
company_volumes <- tibble(
Company = names(company_data_clean),
Mean_Volume = company_volumes
)
# Definir os percentis de 30% e 70%
volume_30 <- quantile(company_volumes$Mean_Volume, 0.3, na.rm = TRUE)
volume_70 <- quantile(company_volumes$Mean_Volume, 0.7, na.rm = TRUE)
# Atribuir cada empresa a um grupo com base na média de volume
company_volumes <- company_volumes %>%
mutate(
Group = case_when(
Mean_Volume <= volume_30 ~ "Low Volume (Bottom 30%)",
Mean_Volume > volume_70 ~ "High Volume (Top 30%)",
TRUE ~ "Middle Volume (40%)"
)
)
# Empresas de baixo volume (Bottom 30%)
low_volume <- company_volumes %>%
filter(Group == "Low Volume (Bottom 30%)") %>%
pull(Company)
# Empresas de alto volume (Top 30%)
high_volume <- company_volumes %>%
filter(Group == "High Volume (Top 30%)") %>%
pull(Company)
# Criando um company_data_clean_high_volume e company_data_clean_low_volume
company_data_clean_high_volume <- company_data_clean[high_volume]
company_data_clean_low_volume <- company_data_clean[low_volume]
# Função para converter dataframe em xts
convert_to_xts <- function(df) {
xts(df[, -1], order.by = as.Date(df$Date))
}
# Converter os dataframes em company_data_clean para xts
company_data_clean_xts <- company_data_clean %>%
map(~ convert_to_xts(.x))
# Calcular os spreads para cada empresa
company_spreads_EDGE <- company_data_clean_xts %>%
map(~ bidask::spread(.x[, 1:4], method = "EDGE", width = 21, na.rm = TRUE))
# Calcular o spread com method "CS" para cada empresa em company_spreads
company_spreads_CS <- company_data_clean_xts %>%
map(~ bidask::spread(.x[, 1:4], method = "CS", width = 21, na.rm = TRUE))
# Calcular o spread com method "AR" para cada empresa em company_spreads
company_spreads_AR <- company_data_clean_xts %>%
map(~ bidask::spread(.x[, 1:4], method = "AR", width = 21, na.rm = TRUE))
# Combine os spreads em uma lista de listas
company_spreads_list <- list(
EDGE = company_spreads_EDGE,
CS = company_spreads_CS,
AR = company_spreads_AR
)
# Obtenha os códigos das empresas
company_codes <- names(company_spreads_EDGE)
# Use pmap_dfr para combinar os spreads em um único dataframe
company_spreads_df <- pmap_dfr(
.l = list(
company_code = company_codes,
edge = company_spreads_EDGE,
cs = company_spreads_CS,
ar = company_spreads_AR
),
.f = function(company_code, edge, cs, ar) {
data.frame(
Company_Code = company_code,
Date = index(edge),
Spread_EDGE = as.numeric(edge),
Spread_CS = as.numeric(cs),
Spread_AR = as.numeric(ar)
)
}
)
# Calcular os spreads médios para cada ano em cada método e aplicar na variável company_spreads_year
company_spreads_year <- company_spreads_df %>%
mutate(Year = year(Date)) %>%
group_by(Company_Code, Year) %>%
summarise(
Spread_EDGE = mean(Spread_EDGE, na.rm = TRUE),
Spread_CS = mean(Spread_CS, na.rm = TRUE),
Spread_AR = mean(Spread_AR, na.rm = TRUE),
)
# Filtrar o company_spread_df para high_volume e low_volume
company_spreads_high_volume <- company_spreads_year %>%
filter(Company_Code %in% high_volume)
company_spreads_low_volume <- company_spreads_year %>%
filter(Company_Code %in% low_volume)
# Filtrar o company_spread_year para os anos de 2017 a 2019 (antes da pandemia), para 2020 e 2021 (durante a pandemia) e para 2022 a 2024 (após a pandemia)
company_spreads_pre <- company_spreads_year %>%
filter(Year %in% 2017:2019)
company_spreads_dur <- company_spreads_year %>%
filter(Year %in% 2020:2021)
company_spreads_pos <- company_spreads_year %>%
filter(Year %in% 2022:2024)
View(company_spreads_AR)
View(company_spreads_year)
