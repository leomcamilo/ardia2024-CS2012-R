---
title: dissertação
author: Leonardo Camilo-da-Silva
date: today
execute: 
  freeze: auto
format: 
  pdf:
    template-partials: 
    - "before-body.tex" 
    latex_engine: xelatex
    mainfont: Times New Roman
    fontsize: 12pt
    lineheight: 1.5
    linestretch: 1.5
    geometry: "left=3cm, top=3cm, right=2cm, bottom=2cm"
    keep-tex: false
    number-sections: true
    include-in-header: config.tex        
crossref:
  fig-title: Figura   
  fig-prefix: figura
  tbl-title: Tabela     
  tbl-prefix: tabela
  lof-title: LISTA DE FIGURAS
  lot-title: LISTA DE TABELAS
  eq-title: Equação
  eq-prefix: equação
tbl-cap-location: top
fig-cap-location: top
lot: true
lof: true
listings: true
toc: true
toc-title: SUMÁRIO
toc-depth: 3
linkcolor: black
link-bibliography: false
editor: visual
# bibliography: references.bib
csl: abnt2023.csl
---

\newpage
\listofequations
\newpage

```{r}
library(tidyverse)
library(quantmod)
library(bidask)
library(readr)
library(purrr)
library(gt)
library(writexl)
```

```{r}
# Importando preços
company_codes <- read_csv("company_codes.csv")

# Baixando preços com Quantmod
getSymbols(company_codes$Company_Code, from = "2018-01-01", to = "2024-10-30", src = "yahoo")

# Calculando spread com Ardia e CS
bidask::spread(SBSP3.SA[,1:4], method = "EDGE", width = 21, na.rm = TRUE)

```

```{r}
# Importar códigos de empresas
company_codes <- read_csv("company_codes.csv")

# Função segura para baixar dados
safe_getSymbols <- safely(function(symbol) {
  getSymbols(symbol, src = "yahoo", from = "2017-01-01", to = "2024-10-30", auto.assign = FALSE)
})

# Aplicar a função a todos os códigos de empresas usando purrr::map
company_data_list <- company_codes$Company_Code %>%
  map(~ safe_getSymbols(.x))

# Extrair os resultados bem-sucedidos e Nomear a lista com os códigos das empresas
company_data_clean <- company_data_list %>%
  map("result") %>%
  set_names(company_codes$Company_Code)

# Verificar quais downloads falharam
errors <- company_data_list %>%
  map("error") %>%
  keep(~ !is.null(.x))

if (length(errors) > 0) {
  print("Alguns downloads falharam:")
  print(errors)
} else {
  print("Todos os dados foram baixados com sucesso.")
}
```

## Seleção dos 30% maiores e 30% menores volumes diários

```{r}
# Agrupar as empresas com maiores médias de volume diários e selecionar os 30% maiores e 30% menores

# Calcular a média de volume para cada empresa
company_volumes <- company_data_clean %>%
  # Extrair a coluna de Volume (coluna 5) de cada dataframe
  map_dbl(~ mean(.x[[5]], na.rm = TRUE))

# Converter os resultados para um dataframe para melhor manipulação
company_volumes <- tibble(
  Company = names(company_data_clean),
  Mean_Volume = company_volumes
)

# Definir os percentis de 30% e 70%
volume_30 <- quantile(company_volumes$Mean_Volume, 0.3, na.rm = TRUE)
volume_70 <- quantile(company_volumes$Mean_Volume, 0.7, na.rm = TRUE)

# Atribuir cada empresa a um grupo com base na média de volume
company_volumes <- company_volumes %>%
  mutate(
    Group = case_when(
      Mean_Volume <= volume_30 ~ "Low Volume (Bottom 30%)",
      Mean_Volume > volume_70 ~ "High Volume (Top 30%)",
      TRUE ~ "Middle Volume (40%)"
    )
  )

# Empresas de baixo volume (Bottom 30%)
low_volume <- company_volumes %>%
  filter(Group == "Low Volume (Bottom 30%)") %>%
  pull(Company)

# Empresas de alto volume (Top 30%)
high_volume <- company_volumes %>%
  filter(Group == "High Volume (Top 30%)") %>%
  pull(Company)

# Criando um company_data_clean_high_volume e company_data_clean_low_volume
company_data_clean_high_volume <- company_data_clean[high_volume]
company_data_clean_low_volume <- company_data_clean[low_volume]

```

## Cálculo dos spreads EDGE e CS para toda a base

```{r}
# Calcular os spreads para cada empresa
company_spreads_EDGE <- company_data_clean %>%
  map(~ bidask::spread(.x[, 1:4], method = "EDGE", width = 21, na.rm = TRUE))

# Calcular o spread com method "CS" para cada empresa em company_spreads
company_spreads_CS <- company_data_clean %>%
  map(~ bidask::spread(.x[, 1:4], method = "CS", width = 21, na.rm = TRUE))

# Juntar company_spreads e company_spreads_CS no mesmo dataframe com colunas de Data, Código, Spread_EDGE e Spread_CS
company_spreads_df <- map2_dfr(company_spreads_EDGE, company_spreads_CS, ~ {
  data_frame(
    Date = index(.x),
    Spread_EDGE = .x,
    Spread_CS = .y
  )
}, .id = "Company_Code")

# Calcular os spreads médios para cada ano em cada método e aplicar na variável company_spreads_year
company_spreads_year <- company_spreads_df %>%
  mutate(Year = year(Date)) %>%
  group_by(Company_Code, Year) %>%
  summarise(
    Spread_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    Spread_CS = mean(Spread_CS, na.rm = TRUE)
  )

# Filtrar o company_spread_df para high_volume e low_volume
company_spreads_high_volume <- company_spreads_year %>%
  filter(Company_Code %in% high_volume)
company_spreads_low_volume <- company_spreads_year %>%
  filter(Company_Code %in% low_volume)

# Filtrar o company_spread_year para os anos de 2017 a 2019 (antes da pandemia), para 2020 e 2021 (durante a pandemia) e para 2022 a 2024 (após a pandemia)
company_spreads_pre <- company_spreads_year %>%
  filter(Year %in% 2017:2019)
company_spreads_dur <- company_spreads_year %>%
  filter(Year %in% 2020:2021)
company_spreads_pos <- company_spreads_year %>%
  filter(Year %in% 2022:2024)


```

### Montando a tabela 1

```{r}
# Atribuir grupos de volumes aos dados de spreads
company_spreads_df <- company_spreads_df %>%
  mutate(Group = case_when(
    Company_Code %in% high_volume ~ "Ativos mais líquidos",
    Company_Code %in% low_volume ~ "Ativos menos líquidos",
    TRUE ~ "Todos"
  ))

# Calcular as estatísticas para cada grupo e método
stats_table <- company_spreads_df %>%
  group_by(Group) %>%
  summarise(
    Média_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    DesvPad_EDGE = sd(Spread_EDGE, na.rm = TRUE),
    Mediana_EDGE = median(Spread_EDGE, na.rm = TRUE),
    Máximo_EDGE = max(Spread_EDGE, na.rm = TRUE),
    Mínimo_EDGE = min(Spread_EDGE, na.rm = TRUE),
    Média_CS = mean(Spread_CS, na.rm = TRUE),
    DesvPad_CS = sd(Spread_CS, na.rm = TRUE),
    Mediana_CS = median(Spread_CS, na.rm = TRUE),
    Máximo_CS = max(Spread_CS, na.rm = TRUE),
    Mínimo_CS = min(Spread_CS, na.rm = TRUE)
  ) %>%
  ungroup()

# Atribuir os grupos na ordem desejada
stats_table$Group <- factor(stats_table$Group,
                            levels = c("Ativos mais líquidos",
                                       "Ativos menos líquidos",
                                       "Todos"))

stats_table <- stats_table %>% arrange(Group)

# Create the table with merged column headings
tabela1 <- stats_table %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "EDGE",
    columns = c("Média_EDGE", "DesvPad_EDGE", "Mediana_EDGE", "Máximo_EDGE", "Mínimo_EDGE")
  ) %>%
  tab_spanner(
    label = "CS",
    columns = c("Média_CS", "DesvPad_CS", "Mediana_CS", "Máximo_CS", "Mínimo_CS")
  ) %>%
  cols_label(
    Média_EDGE = "Média",
    DesvPad_EDGE = "DesvPad",
    Mediana_EDGE = "Mediana",
    Máximo_EDGE = "Máximo",
    Mínimo_EDGE = "Mínimo",
    Média_CS = "Média",
    DesvPad_CS = "DesvPad",
    Mediana_CS = "Mediana",
    Máximo_CS = "Máximo",
    Mínimo_CS = "Mínimo"
  )

# Chamando a tabela
tabela1
```

Ao analisar os resultados obtidos, observa-se que o estimador EDGE apresentou valores mínimos de spread bid-ask de (2{,}205289 \times 10\^{-5}) para ativos mais líquidos e (1{,}571447 \times 10\^{-5}) para ativos menos líquidos. Em contraste, o estimador CS retornou valores iguais a zero para ambos os grupos de ativos. Esses achados estão em consonância com o exposto por Ardia et al. (2024), que investigaram o desempenho de diferentes estimadores de spread bid-ask em função da frequência de negociações.

Segundo Ardia et al. (2024), enquanto todos os estimadores avaliados são não viesados em cenários com alta frequência de negociações (por exemplo, 390 negociações por dia), suas performances divergem significativamente à medida que essa frequência diminui. Especificamente, o estimador CS apresenta um viés negativo acentuado em frequências menores, chegando a estimar spreads nulos em situações com menos de dez negociações diárias. Isso ocorre devido à forte dependência do CS na suposição de que os ativos são negociados continuamente, o que não é válido em mercados com baixa liquidez.

Por outro lado, o EDGE mantém estimativas não viesadas independentemente do número de negociações, graças a um termo de correção analítico que considera a negociação infrequente. Nossos resultados corroboram essa evidência, mostrando que o EDGE não retorna valores nulos mesmo em ativos com baixa frequência de negociação, ao contrário do CS. Dessa forma, o EDGE se apresenta como uma metodologia mais robusta e apropriada para estimar o spread bid-ask em mercados com ativos menos líquidos.

Esses resultados destacam a importância de selecionar estimadores adequados ao contexto de negociação dos ativos analisados, sendo o EDGE uma alternativa superior ao CS em cenários de baixa liquidez.

# Introdução

# Objetivos

## Gerais

## Específicos

# Justificativa

# Referencial Teórico

# Metodologia

# Limitações

# Discussão

# Conclusão

# Conclusão

\newpage

# Bibliografia

# Exportar o data frame stats_table para um arquivo Excel

write_xlsx(stats_table, "tabela1.xlsx")
