---
title: dissertação
author: Leonardo Camilo-da-Silva
date: today
execute: 
  freeze: true     # auto
  echo: false      # Ocultar códigos dos chunks
  warning: false   # Suprimir avisos
  message: false   # Suprimir mensagens
  error: false     # Suprimir erros
lang: pt
format: 
  # docx:
  #   toc: true            # Inclui o sumário
    # reference-doc: template.docx  # (Opcional) Modelo personalizado
    # Adicione outras opções específicas para o Word aqui
  pdf:
    template-partials: 
    - "before-body.tex" 
    latex_engine: xelatex
    mainfont: Times New Roman
    fontsize: 12pt
    lineheight: 1.5
    linestretch: 1.5
    geometry: "left=3cm, top=3cm, right=2cm, bottom=2cm"
    keep-tex: false
    number-sections: true
    include-in-header: config.tex
crossref:
  fig-title: Figura   
  fig-prefix: Figura
  tbl-title: Tabela     
  tbl-prefix: Tabela
  lof-title: LISTA DE FIGURAS
  lot-title: LISTA DE TABELAS
  eq-title: Equação
  eq-prefix: equação
tbl-cap-location: top
fig-cap-location: top
lot: true
lof: true
listings: true
toc: true
toc-title: SUMÁRIO
toc-depth: 3
linkcolor: black
link-bibliography: false
editor: visual
bibliography: references.bib
csl: abnt2023.csl
---

\newpage
\listofequations
\newpage

```{r Carregando as libs}
library(tidyverse)
library(quantmod)
library(bidask)
library(readr)
library(purrr)
library(gt)
library(writexl)
library(readxl)
library(readxl)
library(kableExtra)
```

```{r Importando a base do getSymbols e salvando em csvs individuais, include = FALSE, warning=FALSE, eval = FALSE}
# Importa os códigos das empresas do csv e carrega infos de preços do pacote para um CSV separado individual

# Importar códigos de empresas
company_codes <- read_csv("company_codes.csv")

# Função segura para baixar dados
safe_getSymbols <- safely(function(symbol) {
  getSymbols(symbol, src = "yahoo", from = "2017-01-01", to = "2024-10-30", auto.assign = FALSE)
})

# Baixar e salvar os preços de cada empresa em um arquivo CSV separado
company_codes$Company_Code %>% 
  walk(~ {
    result <- safe_getSymbols(.x)
    if (!is.null(result$result)) {
      data <- result$result
      data <- data.frame(Date = index(data), coredata(data))  # Adicionar a coluna de data
      write.csv(data, file = paste0("prices-companies/", .x, ".csv"), row.names = FALSE)
    } else {
      message("Erro ao baixar dados para: ", .x)
    }
  })
```

```{r importacao dos dados de spread bloomberg e dos csv com preco, include = FALSE, show_col_types = FALSE}
# Importa do CSV que já tem os preços

# Importar códigos de empresas novamente
company_codes <- read_csv("company_codes.csv")

# Função para ler dados de arquivos CSV
read_company_data <- function(symbol) {
  file_path <- paste0("prices-companies/", symbol, ".csv")
  if (file.exists(file_path)) {
    read_csv(file_path)
  } else {
    message("Arquivo não encontrado para: ", symbol)
    NULL
  }
}

# Aplicar a função a todos os códigos de empresas usando purrr::map
company_data_list <- company_codes$Company_Code %>%
  map(~ read_company_data(.x))

# Função para remover linhas com valores NA de um dataframe
remove_na_rows <- function(df) {
  df %>% drop_na()
}

# Filtrar elementos NULL e remover linhas com valores NA
company_data_clean <- company_data_list %>%
  keep(~ !is.null(.x)) %>%
  map(~ remove_na_rows(.x)) %>%
  set_names(company_codes$Company_Code[!map_lgl(company_data_list, is.null)])

# Remover o sufixo ".SA" dos nomes dos elementos na lista company_data_clean
# Verifica se a lista não está vazia antes de tentar renomear
if (length(company_data_clean) > 0) {
  current_names <- names(company_data_clean)
  # Usa gsub para remover ".SA" do final de cada nome
  # \\. escapa o ponto (caractere especial em regex)
  # $ garante que a substituição ocorra apenas no final da string
  new_names <- gsub("\\.SA$", "", current_names)
  names(company_data_clean) <- new_names
}

# Remove todas as variáveis globais terminadas em ".SA"
rm(list = ls(pattern = "\\.SA$"))
rm(company_data_list)
```

```{r criacao dos csv de spread da bloomberg, include=FALSE, warning=FALSE}
### - CRIAÇÃO DA TABELA DO SPREAD BID-ASK, SEM O CALCULO AINDA- ###

# Define o caminho de directory
directory <- "Bloomberg spread"

# Read the Excel file from the directory
bloomberg_data <- read_excel(file.path(directory, "00-Spread-bloomberg.xlsx"), sheet = "Base de dados")

# Get the date column (assuming it's the first column)
date_col <- bloomberg_data[, 1]

# Initialize a list to store individual stock dataframes
stock_dfs <- list()

# Processa cada ação (assumindo grupos de 3 colunas: Last Price, Bid Price, Ask Price)
num_stocks <- (ncol(bloomberg_data) - 1) / 3  # Subtract 1 for date column

for (i in 1:num_stocks) {
  # Calculate column indices
  last_col_idx <- 1 + (i-1)*3 + 1
  bid_col_idx <- 1 + (i-1)*3 + 2
  ask_col_idx <- 1 + (i-1)*3 + 3
  
  # Extract stock name from column header (adjust as needed)
  stock_name <- gsub(" Last Price", "", names(bloomberg_data)[last_col_idx])
  
  # Create dataframe for this stock with explicit conversion to numeric
  stock_df <- data.frame(
    Date = date_col,
    Bid_Price = as.numeric(as.character(bloomberg_data[[bid_col_idx]])),
    Ask_Price = as.numeric(as.character(bloomberg_data[[ask_col_idx]]))
  )
  
  # Calculate bid-ask spread percentage handling NA values
  stock_df$Bid_Ask_Spread_Pct <- ifelse(
    !is.na(stock_df$Ask_Price) & !is.na(stock_df$Bid_Price) & stock_df$Ask_Price > 0 & stock_df$Bid_Price > 0,
    (stock_df$Ask_Price - stock_df$Bid_Price) / ((stock_df$Ask_Price + stock_df$Bid_Price) / 2) * 100,
    NA
  )
  
  # Store in the list
  stock_dfs[[stock_name]] <- stock_df
  
  # Save to CSV in the same directory
  write.csv(stock_df, file = file.path(directory, paste0(stock_name, ".csv")), row.names = FALSE)
}

rm(stock_df)
```

```{r juntar todos os CSV com spread da bloomberg em uma única tabela, include=FALSE, show_col_types = FALSE}
# List all CSV files in the directory that end with "-"
csv_files <- list.files(path = directory, pattern = ".*-\\.csv$", full.names = TRUE)

# Função para ler um arquivo CSV e extrair o código da companhia
read_company_csv <- function(file_path) {
  # Extrair o nome do arquivo sem extensão
  filename <- tools::file_path_sans_ext(basename(file_path))
  
  # Ler o CSV
  data <- read_csv(file_path)
  
  # Primeiro, checar quais são os nomes das colunas
  date_column <- names(data)[grep("Date", names(data), ignore.case = TRUE)]
  
  if (length(date_column) == 0) {
    warning("No date column found in file: ", file_path)
    return(NULL)
  }
  
  # Adicionar a coluna de código da companhia e selecionar somente as colunas necessárias
  data %>%
    mutate(Company_Code = filename) %>%
    select(Company_Code, !!date_column, Bid_Ask_Spread_Pct) %>%
    rename(Date = !!date_column)  # Standardize to "Date"
}

# Ler todos os CSVs e combinar os dados
if (length(csv_files) > 0) {
  # Use safely to handle potential errors
  safe_read <- safely(read_company_csv)
  results <- map(csv_files, safe_read)
  
  # Extract successful results
  valid_data <- map(results, "result") %>% 
    compact()
  
  if (length(valid_data) > 0) {
    spreads_company <- bind_rows(valid_data)
    
    # Clean up company codes by removing hyphens at the end
    spreads_company <- spreads_company %>%
      mutate(Company_Code = str_replace(Company_Code, " -$", ""))
    
    # Save to global environment
    assign("spreads_company", spreads_company, envir = .GlobalEnv)
    
    # Optionally save to CSV
    write_csv(spreads_company, file.path(directory, "spreads_company.csv"))
    
    cat("Created 'spreads_company' with", nrow(spreads_company), "rows and", 
        length(unique(spreads_company$Company_Code)), "unique companies.\n")
  } else {
    cat("No valid data found in any of the CSV files.\n")
  }
} else {
  cat("No CSV files found that end with '-'.\n")
}
```

```{=html}
<!--
Seleção dos 30% maiores e 30% menores volumes diários; Ou seja, maiores e menores liquidez.
-->
```

```{r pegando a liquidez e agrupando, include=FALSE}
# Agrupar as empresas com maiores médias de volume diários e selecionar os 30% maiores e 30% menores

# Define o caminho para o arquivo Excel
file_path_liquidez <- file.path("auxilio", "liquidez-acoes.xlsx")

# Lê o arquivo Excel e salva como dataframe company_volumes
company_volumes <- read_excel(file_path_liquidez)

# Renomear colunas específicas por índice
# Nota: Certifique-se de que os índices das colunas (7, 8, 9) estão corretos para o seu arquivo Excel.
company_volumes <- company_volumes %>%
  rename(
    codigo = names(.)[7],
    liquidez = names(.)[8],
    segmento = names(.)[9]
  )

### - VOLTANDO PARA company_data_clean para filtrar as ações - ###

# Obter os códigos presentes em company_volumes
codigos_volumes <- unique(company_volumes$codigo)

# Filtrar a lista company_data_clean mantendo apenas os elementos com códigos em company_volumes
company_data_clean <- company_data_clean[names(company_data_clean) %in% codigos_volumes]
# Filtrar company_volumes mantendo apenas os elementos com códigos em company_data_clean
company_volumes <- company_volumes %>%
  filter(codigo %in% names(company_data_clean))

### --- ###

# Definir os percentis de 30% e 70%
volume_30 <- quantile(company_volumes$liquidez, 0.3, na.rm = TRUE)
volume_70 <- quantile(company_volumes$liquidez, 0.7, na.rm = TRUE)

# Atribuir cada empresa a um grupo com base na média de volume
company_volumes <- company_volumes %>%
  mutate(
    Group = case_when(
      liquidez <= volume_30 ~ "Low Volume (Bottom 30%)",
      liquidez > volume_70 ~ "High Volume (Top 30%)",
      TRUE ~ "Middle Volume (40%)"
    )
  )

# Empresas de baixo volume (Bottom 30%)
low_volume <- company_volumes %>%
  filter(Group == "Low Volume (Bottom 30%)") %>%
  pull(codigo)

# Empresas de alto volume (Top 30%)
high_volume <- company_volumes %>%
  filter(Group == "High Volume (Top 30%)") %>%
  pull(codigo)

# Criando um company_data_clean_high_volume e company_data_clean_low_volume
company_data_clean_high_volume <- company_data_clean[high_volume]
company_data_clean_low_volume <- company_data_clean[low_volume]

# rm(low_volume,high_volume,volume_30,volume_70,company_volumes)
```

<!--Cálculo dos spreads EDGE e CS para toda a base-->

```{r calculando as estimativas para toda a base, include=FALSE}

# Função para converter dataframe em xts
convert_to_xts <- function(df) {
  xts(df[, -1], order.by = as.Date(df$Date))
}

# Converter os dataframes em company_data_clean para xts
company_data_clean_xts <- company_data_clean %>%
  map(~ convert_to_xts(.x))

# Calcular os spreads para cada empresa
company_spreads_EDGE <- company_data_clean_xts %>%
  map(~ bidask::spread(.x[, 1:4], method = "EDGE", width = 21, na.rm = TRUE))

# Calcular o spread com method "CS" para cada empresa em company_spreads
company_spreads_CS <- company_data_clean_xts %>%
  map(~ bidask::spread(.x[, 1:4], method = "CS", width = 21, na.rm = TRUE))

# Calcular o spread com method "AR" para cada empresa em company_spreads
company_spreads_AR <- company_data_clean_xts %>%
  map(~ bidask::spread(.x[, 1:4], method = "AR", width = 21, na.rm = TRUE))

# Combine os spreads em uma lista de listas
company_spreads_list <- list(
  EDGE = company_spreads_EDGE,
  CS = company_spreads_CS,
  AR = company_spreads_AR
)

# Obtenha os códigos das empresas
company_codes <- names(company_spreads_EDGE)

# Use pmap_dfr para combinar os spreads em um único dataframe
company_spreads_df <- pmap_dfr(
  .l = list(
    company_code = company_codes,
    edge = company_spreads_EDGE,
    cs = company_spreads_CS,
    ar = company_spreads_AR
  ),
  .f = function(company_code, edge, cs, ar) {
    data.frame(
      Company_Code = company_code,
      Date = index(edge),
      Spread_EDGE = as.numeric(edge),
      Spread_CS = as.numeric(cs),
      Spread_AR = as.numeric(ar)
    )
  }
)

# Primeiro, remove o sufixo ".SA" dos códigos das empresas em company_spreads_df
company_spreads_df <- company_spreads_df %>%
  mutate(Company_Code = str_replace(Company_Code, "\\.SA$", ""))

# Renomeie a coluna Bid_Ask_Spread_Pct para Spread_Bloomberg
spreads_bloomberg <- spreads_company %>%
  rename(Spread_Bloomberg = Bid_Ask_Spread_Pct)

# Junte os dataframes baseado em Company_Code e Date
company_spreads_df_with_bloomberg <- left_join(
  company_spreads_df,
  spreads_bloomberg %>% select(Company_Code, Date, Spread_Bloomberg),
  by = c("Company_Code", "Date")
)

# Verifique os resultados
cat("Número de linhas no dataframe original:", nrow(company_spreads_df), "\n")
cat("Número de linhas após junção com dados Bloomberg:", nrow(company_spreads_df_with_bloomberg), "\n")
cat("Número de correspondências encontradas (não-NA):", sum(!is.na(company_spreads_df_with_bloomberg$Spread_Bloomberg)), "\n")

# Substituir o dataframe original
company_spreads_df <- company_spreads_df_with_bloomberg
rm(company_spreads_df_with_bloomberg)

# 
company_spreads_df <- company_spreads_df %>%
  mutate(Group = case_when(
    Company_Code %in% high_volume ~ "High Volume (Top 30%)",
    Company_Code %in% low_volume ~ "Low Volume (Bottom 30%)",
    TRUE ~ "Middle Volume (40%)"
  ))
  
# Calcular os spreads médios para cada ano em cada método e aplicar na variável company_spreads_year
company_spreads_year <- company_spreads_df %>%
  mutate(Year = year(Date)) %>%
  group_by(Company_Code, Group, Year) %>%
  summarise(
    Spread_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    Spread_CS = mean(Spread_CS, na.rm = TRUE),
    Spread_AR = mean(Spread_AR, na.rm = TRUE),
    Spread_Bloomberg = mean(Spread_Bloomberg, na.rm = TRUE)
  )

# Filtrar o company_spread_df para high_volume e low_volume
company_spreads_high_volume <- company_spreads_year %>%
  filter(Company_Code %in% high_volume)
company_spreads_low_volume <- company_spreads_year %>%
  filter(Company_Code %in% low_volume)

# Filtrar o company_spread_year para os anos de 2018 a 2019 (antes da pandemia), para 2020 (durante a pandemia) e para 2021 a 2022 (após a pandemia)
company_spreads_pre <- company_spreads_year %>%
  filter(Year %in% 2018:2019)
company_spreads_dur <- company_spreads_year %>%
  filter(Year %in% 2020)
company_spreads_pos <- company_spreads_year %>%
  filter(Year %in% 2021:2022)


```

# Introdução

## Contexto

O spread bid-ask é uma medida fundamental na microestrutura de mercado, representando a diferença entre os preços de compra (bid) e venda (ask) de um ativo. Este spread reflete os custos de transação e a liquidez do mercado, sendo influenciado por fatores como a volatilidade do ativo, a frequência de negociação e a assimetria de informações entre os participantes do mercado. A análise do spread bid-ask é crucial para entender a eficiência do mercado e os custos enfrentados pelos investidores.

No contexto dos mercados emergentes, a B3 (Brasil, Bolsa, Balcão) desempenha um papel central. A B3 é um importante centro de negociação de ativos financeiros na América Latina, ela não só facilita a negociação de ações, mas também de derivativos, títulos de renda fixa e outros instrumentos financeiros. A bolsa tem se destacado por sua infraestrutura tecnológica avançada e por iniciativas voltadas à inclusão financeira e ao aumento da liquidez do mercado. No entanto, os mercados emergentes, como o brasileiro, ainda enfrentam desafios significativos, incluindo menor liquidez e maior volatilidade em comparação com mercados desenvolvidos.

A literatura sobre spread bid-ask tem evoluído significativamente ao longo das últimas décadas, com diversos métodos sendo desenvolvidos para sua estimativa. Métodos tradicionais, como o estimador de Roll (1984), foram complementados por abordagens mais recentes, como os estimadores de Corwin e Schultz (2012) e de Abdi e Ranaldo (2017). Apesar desses avanços, há uma lacuna notável na aplicação dessas técnicas a mercados emergentes. A maioria dos estudos concentra-se em mercados desenvolvidos, deixando uma lacuna na compreensão de como essas abordagens se comportam em contextos de menor liquidez e maior volatilidade, como o mercado brasileiro.

### Relevância e justificativa

Medir o spread bid-ask é de extrema relevância para diversos stakeholders no mercado financeiro. Corwin (2012) destaca que, para os investidores, o spread bid-ask é um indicador direto dos custos de transação e da liquidez do mercado, influenciando decisões de compra e venda de ativos. Reguladores utilizam essa medida para monitorar a eficiência do mercado e identificar possíveis práticas de manipulação de preços. Acadêmicos, por sua vez, empregam o spread bid-ask como uma variável chave em estudos sobre microestrutura de mercado, eficiência de preços e assimetria informacional.

Este trabalho busca preencher lacunas importantes na literatura ao realizar uma análise comparativa de métodos de estimativa do spread bid-ask aplicadas ao mercado brasileiro. Ripamonti (2016) observa que a ausência de estudos que comparam diferentes técnicas nesse contexto específico representa uma oportunidade para contribuir com novos insights sobre a eficiência e a liquidez do mercado brasileiro. Os resultados deste estudo podem auxiliar investidores na seleção de ações e na avaliação de riscos de liquidez, fornecendo uma base mais sólida para suas decisões de investimento.

A escolha do mercado brasileiro se justifica por suas características únicas como mercado emergente. A B3, com sua estrutura de mercado order-driven e sua diversidade de ativos e participantes, oferece um ambiente ideal para testar a robustez das metodologias de estimativa do spread bid-ask. Além disso, Ripamonti (2016) sugere que os resultados obtidos podem ser generalizados para outros mercados emergentes com características semelhantes, ampliando o impacto e a relevância do estudo. Dessa forma, este trabalho não só contribui para a literatura acadêmica, mas também oferece implicações práticas para investidores e reguladores no contexto de mercados emergentes.

\newpage

# Objetivos

Considerando a relevância do spread bid-ask na formação de preços de ativos financeiros e seu impacto na liquidez e nos custos de transação, este estudo tem como objetivo geral comparar, no mercado acionário brasileiro, estimativas de spread bid-ask obtidas pelas abordagens de Corwin & Schultz (2012), Abdi & Ranaldo (2017) e EDGE (Ardia, Guidotti & Kroencke, 2024), tendo como referência a cotação de spread divulgada pela Bloomberg.

A análise comparativa das metodologias selecionadas abrangerá tanto períodos de relativa estabilidade quanto momentos de volatilidade acentuada, com especial atenção ao período da pandemia de COVID-19 em 2020. Esta abordagem permitirá avaliar não apenas a precisão geral dos estimadores, mas também sua robustez e capacidade de capturar as variações nos custos de transação em condições extremas de mercado, fornecendo insights valiosos sobre a microestrutura do mercado brasileiro em diferentes contextos econômicos.

\newpage

# Referencial teórico

## Hipótese de eficiência de mercado

De acordo com Fama (1970) a Hipótese de eficiência de mercado propõe que os investidores do mercado irão fazer a melhor alocação de ativos possível com todas as informações relevantes que terão acesso, e os preços dos ativos irá refletir todas as informações disponíveis para os investidores, que se basearão na teoria econômica para realizar tais cálculos. Em Finanças, a HEM (Hipótese da Eficiência de Mercado) afirma que os mercados financeiros são "eficientes em relação à informação". Ou seja, um agente não consegue alcançar consistentemente retornos superiores à média do mercado, considerando as informações publicamente disponíveis no momento em que o investimento é feito (Fama, 1965; Malkiel, 2007; Jensen, 1978).

Existem três versões principais da hipótese: a fraca, a semi-forte e a forte. A hipótese fraca considera que os preços negociados para os bens (por exemplo, ações, obrigações ou propriedade) refletem toda a informação histórica disponível publicamente. Em seu trabalho seminal, Fama (1965) demonstra que os preços em mercados eficientes seguem um passeio aleatório, refletindo todas as informações históricas disponíveis, o que implica que os preços futuros não podem ser previstos com base em padrões passados.

A hipótese semi-forte afirma que os preços refletem todas as informações publicamente disponíveis e que os preços mudam instantaneamente para refletir as novas informações públicas. Esse conceito é extensivamente discutido no trabalho de Fama (1970), onde ele categoriza a eficiência de mercado em formas fraca, semi-forte e forte. A forma semi-forte da HEM sugere que nem mesmo a análise fundamentalista pode proporcionar vantagens, pois todas as informações disponíveis publicamente já estão incorporadas nos preços dos ativos. Estudos empíricos, como os de Malkiel (2007), corroboram essa visão ao demonstrar que as tentativas de prever movimentos de preços com base em análises fundamentais geralmente não resultam em retornos acima da média.

Embora a hipótese de eficiência de mercado proponha que os preços dos ativos refletem todas as informações disponíveis, o spread bid-ask é um fator crucial que pode introduzir ineficiências no mercado. Custos de transação elevados, informação assimétrica, baixa liquidez e problemas de microestrutura do mercado são elementos que podem ampliar o spread e impedir que os preços se ajustem rapidamente às novas informações. Isso sugere que, na prática, os mercados podem não ser tão eficientes quanto a teoria propõe, e os investidores precisam considerar esses fatores ao tomar decisões de investimento.

## Microestrutura de mercado

A microestrutura de mercado é um campo de estudo que analisa os mecanismos e processos pelos quais os preços dos ativos são formados nos mercados financeiros. Este campo abrange uma variedade de tópicos, incluindo a organização e funcionamento dos mercados, o comportamento dos participantes do mercado, e os custos de transação. Segundo Harris (2003), a microestrutura de mercado examina como a estrutura do mercado e os mecanismos de negociação afetam a formação de preços, a liquidez e a eficiência do mercado.

Compreender a microestrutura é fundamental para analisar como as informações são incorporadas nos preços e como os custos de transação influenciam as decisões de investimento. Os mercados financeiros podem ser organizados de várias maneiras, incluindo mercados de leilão e mercados de dealer. Em mercados de leilão, como as bolsas de valores, os preços são estabelecidos através de leilões competitivos, onde compradores e vendedores submetem ordens que são combinadas para formar o preço de mercado. Nos mercados de dealer, como o mercado de câmbio, os dealers fornecem liquidez ao comprar e vender ativos de seu próprio inventário.

Harris (2003) destaca a importância do livro de ordens, que registra todas as ordens de compra e venda pendentes e desempenha um papel crucial na determinação dos preços de mercado. A liquidez do mercado, definida por como a facilidade com que um ativo pode ser comprado ou vendido sem causar uma mudança significativa em seu preço, é fortemente influenciada pela microestrutura do mercado (Harris, 2003). Chordia, et. al (2000) mostram que a estrutura do mercado e a presença de intermediários financeiros desempenham um papel vital na determinação da liquidez. A presença de market makers, por exemplo, pode aumentar a liquidez ao fornecer cotações firmes de compra e venda e ao absorver temporariamente desequilíbrios entre oferta e demanda. Além disso, a profundidade do livro de ordens e a quantidade de informações disponíveis aos participantes do mercado também afetam a liquidez.

Os custos de transação são um componente crucial da microestrutura de mercado e têm um impacto significativo na eficiência do mercado. Stoll (1989) e Glosten e Milgrom (1985) identificam três principais componentes dos custos de transação: custos de processamento das ordens, custos de assimetria de informação e custos de inventário. Os custos de processamento referem-se aos custos operacionais incorridos pelos intermediários ao executar ordens de compra e venda. Os custos de assimetria de informação surgem da incerteza sobre a informação que outros participantes do mercado possuem. Já os custos de inventário são os custos associados à manutenção de um estoque de ativos para facilitar a negociação. A eficiência do mercado é afetada por esses custos, pois eles influenciam a capacidade dos preços refletirem todas as informações disponíveis.

As inovações tecnológicas, particularmente o trading eletrônico e os algoritmos de negociação, têm transformado a microestrutura dos mercados financeiros. Hendershott, Jones e Menkveld (2011) investigam o impacto do trading algorítmico na liquidez do mercado e concluem que ele melhora a liquidez ao aumentar a frequência e a velocidade das transações. A introdução de plataformas de negociação eletrônica reduziu os custos de transação e aumentou a transparência do mercado, permitindo uma melhor incorporação de informações nos preços. No entanto, essas inovações também trazem desafios, como a necessidade de regulamentos adequados para mitigar os riscos associados ao trading de alta frequência e para garantir a estabilidade do mercado.

## Spread de oferta e compra (spread bid-ask)

Custos de inventário ou de estoque, segundo De Jong e Rindi (2009), existem apenas em mercados quote-driven, pois nesses mercados os formadores têm a obrigação de fornecer preços de compra e preços de venda ininterruptamente ao mercado. Os custos relacionados à assimetria de informação e de transação ou de processamento de ordens existem em qualquer mercado. O mercado de ações da B3 é order-driven e nesse caso não se identifica o custo de estoque.

Nos mercados quote-driven, também conhecidos como mercados de dealer, um intermediário (dealer) participa de todas as transações. Nesse tipo de mercado, os traders negociam diretamente com o dealer, que fornece cotações dos preços de compra e venda, assumindo o lado oposto de cada transação e, assim, proporcionando liquidez ao mercado. Esses mercados são comuns no comércio de moedas estrangeiras e títulos no mercado de balcão (OTC).

Por outro lado, nos mercados order-driven, os compradores e vendedores negociam diretamente entre si, sem a intervenção de um dealer, utilizando um conjunto de regras de negociação estabelecidas. Essas regras incluem precedência de ordens, que determina como as ordens de compra e venda são casadas, e regras de precificação de transações. Os mercados order-driven são prevalentes em bolsas de futuros, ações e opções, bem como em redes eletrônicas de comunicação para negociação de títulos e moedas. Em suma, a principal diferença reside no papel do intermediário: enquanto nos mercados quote-driven o dealer facilita todas as transações fornecendo cotações, nos mercados order-driven, as transações são realizadas diretamente entre os traders com base em regras de mercado (Peat, 2009).

No contexto do mercado de ações no Brasil, a B3 adota um modelo de mercado order-driven, mas algumas ações contam com a presença de formadores de mercado. Os formadores de mercado, ou market makers, são contratados pelas empresas para aumentar a liquidez de suas ações. A liquidez refere-se à facilidade com que um ativo pode ser comprado ou vendido sem causar uma mudança significativa em seu preço (Harris, 2003). A presença de um formador de mercado pode reduzir o spread de compra e venda, o que diminui os custos de transação para os investidores e aumenta a atratividade da ação. Empresas contratam formadores de mercado para aumentar a liquidez de suas ações, melhorar a precificação e atrair mais investidores, especialmente em períodos de baixa negociação ou para novos papéis que estão sendo introduzidos no mercado.

A assimetria de informação, por sua vez, ocorre quando diferentes participantes do mercado têm diferentes níveis de acesso à informação relevante para a precificação dos ativos. Nos mercados order-driven, a assimetria de informação pode ser mitigada pela transparência do livro de ordens e pelas regras claras de negociação. No entanto, a assimetria ainda pode existir, especialmente em mercados menos líquidos ou em ações com menor cobertura de analistas. Em mercados quote-driven, a assimetria de informação pode ser mais pronunciada, pois os dealers podem ter acesso a informações privilegiadas que não estão disponíveis para todos os participantes do mercado.

Além disso, os custos de transação referem-se aos custos associados à realização de uma transação econômica, que incluem os custos de negociação e de contratação (Demsetz, 1968). Esses custos incluem taxas pagas à bolsa, comissões de corretagem e custos relacionados ao tempo e esforço necessários para processar as ordens. Em mercados order-driven como a B3, esses custos podem ser reduzidos pela automação e eficiência das plataformas de negociação eletrônica, que facilitam a correspondência rápida e precisa das ordens de compra e venda.

Em suma, a presença de formadores de mercado em ações na B3 visa principalmente aumentar a liquidez, reduzir o spread de compra e venda e melhorar a eficiência do mercado. Ao contratar formadores de mercado, as empresas buscam criar um ambiente de negociação mais ativo e atraente para os investidores, promovendo assim uma melhor precificação e maior volume de negociações. A compreensão dos diferentes custos associados ao spread de compra e venda, bem como das diferenças entre mercados quote-driven e order-driven, é essencial para avaliar o impacto da microestrutura de mercado na formação de preços dos ativos financeiros.

## Modelos de estimação de Spread bid-ask

A mensuração do spread bid-ask pode ser realizada por meio de dados de alta frequência, que registram de forma contínua as cotações e negociações ao longo do dia, ou através de dados de baixa frequência, os quais utilizam informações agregadas, como os preços de fechamento, máxima e mínima diários. Em contextos onde os dados de alta frequência são escassos ou de difícil acesso, os métodos de estimação baseados em dados agregados tornam-se fundamentais para a avaliação dos custos de transação e da liquidez dos ativos.

Para fundamentar este trabalho, foi realizada uma Revisão Narrativa de Literatura (RNL) durante a etapa de qualificação desta dissertação, a qual permitiu identificar os métodos mais relevantes e inovadoras no campo da estimação do spread bid-ask. A partir dessa revisão, foram selecionadas três técnicas de estimação de baixa frequência que vêm contribuindo de maneira significativa para aprimorar a medição do spread bid-ask e que apresentam potencial aplicabilidade ao mercado brasileiro.

A abordagem de Corwin e Schultz (2012) introduz uma forma simplificada de inferir o spread a partir das oscilações diárias, enquanto a proposta de Abdi e Ranaldo (2017) aprimora esse método ao reduzir incertezas inerentes às estimativas com dados diários. Por fim, a metodologia de Ardia, Guidotti e Kroencke (2024) integra informações adicionais, como o preço de abertura, proporcionando uma estimativa mais robusta e precisa.

O modelo de Corwin e Schultz (2012) foi um dos primeiros a propor uma metodologia baseada apenas em preços diários de máxima e mínima para estimar o spread bid-ask. A ideia central do modelo é que o intervalo entre os preços mais altos e mais baixos de um dia reflete tanto a volatilidade do ativo quanto a diferença entre os preços de compra e venda. Assim, os autores derivam um estimador baseado na comparação entre a soma dos intervalos de dois dias consecutivos e o intervalo total de dois dias. Esse modelo trouxe uma abordagem simples e aplicável a mercados onde não há disponibilidade de dados de cotações intradiárias​

Abdi e Ranaldo (2017) expandiram essa metodologia ao incluir informações do preço de fechamento, além dos preços de máxima e mínima diários. O modelo desenvolvido pelos autores tem como premissa a ideia de que o preço de fechamento contém informações adicionais sobre o comportamento do spread bid-ask. Utilizando uma formulação matemática que combina essas três variáveis, o estimador proposto por Abdi e Ranaldo mostrou-se mais preciso para ativos com menor liquidez, superando modelos anteriores em termos de correlação com medidas de spread obtidas a partir de dados de alta frequência​

Mais recentemente, Ardia, Guidotti e Kroencke (2024) propuseram um modelo ainda mais abrangente, que incorpora informações dos preços de abertura, máxima, mínima e fechamento. Diferentemente dos modelos anteriores, que ignoram o preço de abertura, essa nova abordagem busca reduzir vieses na estimação ao aproveitar um conjunto mais completo de informações de preços. Além disso, os autores desenvolveram um estimador eficiente que minimiza a variância da estimativa, tornando-se uma alternativa superior para mensurar spreads em mercados com diferentes níveis de liquidez. O modelo de Ardia et al. (2024) representa um avanço na literatura ao abordar problemas de viés e eficiência estatística na estimação do spread bid-ask​

Dessa forma, a evolução dos métodos de estimação do spread bid-ask reflete a necessidade de desenvolver modelos que equilibrem simplicidade e precisão, especialmente em mercados onde dados de alta frequência não estão disponíveis. A aplicação desses modelos ao mercado brasileiro permite uma avaliação mais detalhada da liquidez dos ativos e dos custos de transação, contribuindo para uma melhor compreensão das dinâmicas de precificação no mercado acionário nacional. Além disso, tais estimadores são fundamentais para o desenvolvimento de programas computacionais que viabilizem a estimação contínua do spread bid-ask, permitindo uma análise mais eficiente do comportamento do mercado.

## Revisão Narrativa de Literatura

Para fundamentar a compreensão teórica e metodológica deste estudo, foi realizada uma Revisão Narrativa de Literatura (RNL), diferenciando-se da Revisão Sistemática de Literatura (RSL) por permitir maior flexibilidade na seleção e análise dos estudos. A abordagem qualitativa e descritiva da RNL possibilitou explorar e sintetizar os principais achados e teorias relacionadas ao spread bid-ask e sua influência na formação de preços de ativos financeiros. A escolha desta metodologia se justificou pela necessidade de construir um panorama mais amplo sobre o spread bid-ask no contexto brasileiro, onde a literatura ainda é incipiente.

A RNL foi conduzida nas bases de dados Web of Science, Scopus, Periódicos Capes e Google Scholar, com foco na identificação de estudos que respondessem à questão central: "O artigo identificou que o spread bid-ask é importante para a formação de preços?". Foram selecionados 19 artigos, divididos entre artigos seminais internacionais (11) e estudos específicos sobre o mercado brasileiro (8). Os critérios de inclusão contemplaram estudos que abordassem diretamente a relação entre o spread bid-ask e a formação de preços, utilizando diversas metodologias e tipos de dados. Estudos sem análise empírica ou indisponíveis em texto completo foram excluídos.

A análise dos artigos selecionados revelou que a maioria dos estudos utilizou modelos econométricos, especialmente regressões de Mínimos Quadrados Ordinários (MQO), para investigar a influência do spread bid-ask na formação de preços. Quanto aos tipos de dados, predominaram pesquisas com dados de baixa frequência, como preços diários de abertura, fechamento, máximo e mínimo. Os mercados examinados incluíram tanto o mercado brasileiro quanto mercados internacionais, com destaque para estudos sobre o mercado de ações e debêntures no Brasil (SND) e o mercado de ações dos Estados Unidos (NYSE). Os aspectos mais analisados foram custos de transação, liquidez, assimetria de informação e volatilidade.

Os resultados da RNL confirmaram a relevância do spread bid-ask como componente essencial na microestrutura de mercado, influenciando diretamente a liquidez, os custos de transação e a eficiência dos mercados financeiros. Identificou-se uma clara evolução metodológica na estimativa do spread bid-ask, desde abordagens clássicas como a de Roll (1984) até estimadores contemporâneos como os de Corwin e Schultz (2012), Abdi e Ranaldo (2017) e Ardia, Guidotti e Kroencke (2024). Esta evolução reflete a busca por metodologias mais precisas e adaptáveis a diferentes contextos de mercado, especialmente em mercados emergentes com características de liquidez heterogêneas. A RNL foi fundamental para identificar as três metodologias utilizadas no presente estudo, selecionadas por sua robustez teórica, ampla aceitação na literatura e capacidade de oferecer insights em diferentes contextos de mercado, especialmente para o caso brasileiro.

\newpage

# Metodologia

Este estudo foi desenvolvido para permitir uma análise rigorosa e comparativa das diferentes metodologias de estimativa do spread bid-ask no mercado de ações brasileiro. A seguir, são detalhadas as etapas e procedimentos adotados para a coleta e análise dos dados, bem como a aplicação das metodologias selecionadas.

## Amostra

A base de dados deste estudo foi composta a partir das informações de preços diários das ações listadas na B3, aplicando critérios rigorosos de seleção para garantir a representatividade e a qualidade dos dados utilizados. O critério principal para inclusão das ações na amostra foi o índice de liquidez, calculado conforme o método descrita por Andrade et al. (2009). Foram consideradas apenas as ações com índice de liquidez superior a 0,1, calculado com base em uma janela de seis meses de dados, assegurando a representatividade de ativos com maior frequência de negociação.

A amostra final é composta por 130 ações, distribuídas entre os diferentes segmentos de governança corporativa da B3. Entre elas, 93 pertencem ao Novo Mercado, 16 ao Nível 2, 17 ao Nível 1 e 4 ao segmento Tradicional. Essa segmentação reflete distintos níveis de práticas de governança corporativa, permitindo uma análise abrangente sobre como essas características impactam os spreads bid-ask e a liquidez dos ativos.

A definição da amostra seguiu abordagens amplamente utilizadas na literatura, como a adotada por Andrade et al. (2009), que empregaram critérios de liquidez para selecionar empresas listadas. Empresas do setor financeiro foram excluídas devido às particularidades de suas demonstrações contábeis, que poderiam introduzir vieses na análise. Além disso, foram descartadas companhias com dados incompletos ou inconsistentes, assegurando que a amostra final apresentasse informações confiáveis para a investigação empírica.

O processo de filtragem das ações visou garantir a robustez dos dados utilizados, selecionando ativos que refletissem, de forma mais precisa, o valor de mercado real. A inclusão de ações com maior liquidez não apenas melhora a representatividade da amostra, mas também favorece a precisão das estimativas econométricas realizadas no estudo, reduzindo potenciais vieses causados por falta de negociação.

## Modelos econométricos

Este estudo aplicou três métodos amplamente reconhecidos para a estimativa do spread bid-ask: CS, AR e EDGE utilizando dados obtidos diretamente da B3. Essas abordagens foram selecionadas devido à sua robustez teórica, ampla aceitação na literatura e capacidade de oferecer insights em diferentes contextos de mercado.

Os artigos que fundamentam estes métodos apresentam significativo impacto acadêmico, evidenciado pelo número de citações: o modelo de Corwin e Schultz (2012) possui 1387 citações, seguido pelo método de Abdi e Ranaldo (2017) com 404 citações e o recente EDGE de Ardia, Guidotti e Kroencke (2024) com 18 citações, conforme dados do Google Scholar em abril de 2025. Esses números refletem a relevância e a aceitação das metodologias na comunidade acadêmica, destacando sua importância na análise do spread bid-ask e na microestrutura de mercado.

O estimador de spread bid-ask desenvolvido por Corwin e Schultz (2012) utiliza os preços diários de máxima e mínima das ações para calcular o spread de forma simples e eficiente. A metodologia parte de duas premissas principais. Primeiramente, assume-se que os preços máximos tendem a ser resultados de ordens de compra, enquanto os mínimos são influenciados por ordens de venda. Dessa forma, a relação entre os preços de máxima e mínima reflete tanto a volatilidade fundamental do ativo quanto os custos associados ao spread bid-ask. Em segundo lugar, considera-se que a componente de volatilidade aumenta proporcionalmente com o intervalo de negociação, enquanto a parte do spread permanece constante.

Matematicamente, o estimador é definido pela seguinte expressão:

$$S = \frac{2 (e^\alpha - 1)}{1 + e^\alpha},$$ {#eq-estimador-cs} \equations{Estimador CS}

onde $S$ representa o spread bid-ask estimado e $e^\alpha$ denota a função exponencial de \alpha com base $e$ (número de Euler). O parâmetro $\alpha$ é calculado por:

$$\alpha = \frac{\sqrt{2\beta} - \sqrt{\beta}}{3 - 2\sqrt{2}} - \sqrt{\frac{\gamma}{3 - 2\sqrt{2}}},$$ {#eq-param-alpha-cs} \equations{Parâmetro $\alpha$ do estimador CS}

sendo $\beta$ e $\gamma$ definidos a partir dos logaritmos naturais das razões entre os preços máximos, H, e mínimos, L, observados:

$$\beta = E\left[\sum_{j=0}^{1} \left( \ln \frac{H_{t+j}}{L_{t+j}} \right)^2 \right],$$ {#eq-param-beta-cs} \equations{Parâmetro $\beta$ do estimador CS}

$$\gamma = E\left[ \left( \ln \frac{H_{t,t+1}}{L_{t,t+1}} \right)^2 \right],$$ {#eq-param-gamma-cs} \equations{Parâmetro $\gamma$ do estimador CS}

onde $$H_{t,t+1} = \max(H_t, H_{t+1})$$ {#eq-param-high-cs} \equations{Parâmetro $High$ de $\beta$ e $\gamma$ do Estimador CS}

e $$L_{t,t+1} = \min(L_t, L_{t+1})$$ {#eq-param-low-cs} \equations{Parâmetro $Low$ de $\beta$ e $\gamma$ do Estimador CS}

Nesse contexto, a @eq-param-beta-cs captura as variações diárias entre os preços máximos e mínimos, enquanto a @eq-param-gamma-cs reflete a dinâmica entre dois dias consecutivos. Essas variáveis permitem separar a volatilidade fundamental do ativo da componente relacionada ao spread bid-ask.

A partir dessas definições, torna-se evidente que o método permite isolar o impacto do spread bid-ask dos movimentos puramente voláteis do preço. A implementação do estimador é direta, dispensando iterações complexas, o que facilita sua aplicação prática em grandes conjuntos de dados. Corwin e Schultz (2012) validaram o estimador por meio de simulações que replicaram condições realistas de mercado, demonstrando que a correlação entre os valores estimados pelo método e os spreads reais é elevada, em torno de 0,9. Em comparação com o estimador de covariância de Roll (1984), o desvio padrão das estimativas de Corwin e Schultz é cerca de metade, indicando maior estabilidade nos resultados.

O método foi aplicado a ações de 11 países, incluindo o Brasil (Ripamonti, 2016; Ichimura, Videira, Ripamonti, 2020), evidenciando sua eficácia em medir os custos de transação em diferentes contextos de liquidez e volatilidade. Essa técnica tem sido amplamente utilizada em estudos sobre microestrutura de mercado. Por exemplo, foi empregada para analisar a relação entre a qualidade das informações financeiras e a assimetria informacional, com resultados que destacaram sua eficiência em comparação a outros indicadores. Embora algumas pesquisas apontem limitações no uso do método como medida de liquidez para prever retornos, ele continua sendo uma ferramenta confiável para estimar custos de transação e compreender a dinâmica dos mercados financeiros.

Portanto, o estimador de Corwin e Schultz (2012) oferece uma solução prática e robusta para mensurar o spread bid-ask com base em dados diários, sendo amplamente adotado em estudos de microestrutura, especialmente em mercados onde dados intradiários são limitados. Sua simplicidade e eficácia tornam-no uma ferramenta valiosa para analisar a liquidez e a eficiência do mercado financeiro brasileiro.

Já o estimador de Abdi e Ranaldo (2017) trouxe uma abordagem nova para o cálculo do spread, sendo desenvolvida para estimar o spread bid-ask utilizando preços diários de fechamento, máxima e mínima das ações. A abordagem se baseia na decomposição do spread em componentes de volatilidade e custos de transação, permitindo uma análise detalhada dos fatores que influenciam a formação de preços nos mercados financeiros. Esse estimador é fundamentado em três etapas principais. Primeiro, utiliza-se o preço médio entre a máxima e a mínima (mid-range) como um proxy para o preço eficiente, que é definido como: $$MR_t = \frac{H_t + L_t}{2}$$ {#eq-mid-range-AR} \equations{Preço médio para cálculo do Estimador AR} Supondo que o spread bid-ask se cancela nesse cálculo.

Em seguida, calcula-se a distância quadrática entre o preço de fechamento e o proxy de preço eficiente derivado da média das médias de dois dias consecutivos, com essa distância sendo representada como: $$D_t = \left(C_t - MR_t\right)^2$$ {#eq-dist-quad-AR} \equations{Distância quadrática entre o Preço de Fechamento e o Proxy de Preço Eficiente} Por fim, essa distância é ajustada para remover a variância do preço eficiente, $\sigma^2_D,$ isolando assim o componente relacionado ao spread bid-ask. Essa abordagem, além de simplificar cálculos, não requer ajustes *ad hoc* para períodos sem negociação, como finais de semana e feriados, o que a torna menos suscetível a viéses comuns em outros modelos.

No final, a fórmula do estimador é dada por:

$$S = 2\sqrt{\sigma^2_D},$$ {#eq-estimador-AR} \equations{Estimador AR}

onde $S$ é o spread bid-ask estimado, e $\sigma^2_D$ é a variância do termo $D_t$, ajustada com base nos preços de dois dias consecutivos. Essa formulação permite capturar de maneira mais precisa os custos de transação associados às negociações

Adicionalmente, o modelo de Abdi e Ranaldo (2017) se destaca em cenários de baixa liquidez. Ao contrário do estimador de Corwin-Schultz (2012), que apresenta viés descendente em ativos menos líquidos, esse método AR foi dito como mais estável e robusto em condições de mercado desafiadoras, o tornando uma ferramenta valiosa para analisar a eficiência e a liquidez em mercados emergentes e em desenvolvimento, onde a disponibilidade de dados intradiários é limitada. A relevância desse estimador é evidente ao compará-lo com outros modelos, como o de Corwin-Schultz. Enquanto o estimador de Corwin-Schultz depende de uma estrutura não-linear para decompor a volatilidade do preço e o spread bid-ask, o modelo de Abdi e Ranaldo (2017) utiliza uma solução em forma fechada, simplificando o processo de estimação e reduzindo a necessidade de premissas adicionais, como a igualdade de chances de preços de alta e baixa serem iniciados por compradores ou vendedores.

Além disso, o método é amplamente aplicável, tendo sido validado em Abdi e Ranaldo (2017) em uma extensa amostra de ações nos EUA desde 1926, demonstrando alto grau de correlação com spreads efetivos medidos por dados intradiários (TAQ). Isso confirma sua eficácia como uma ferramenta para mensurar custos de transação e liquidez em longos períodos históricos, contribuindo para a análise de risco de liquidez sistemática e de commonality em liquidez.

No trabalho de Abdi e Ranaldo (2017), TAQ refere-se ao banco de dados "Trade and Quote", que contém registros detalhados de negociações e cotações de ativos financeiros em alta frequência. Segundo Abdi e Ranaldo (2017), este banco de dados é amplamente reconhecido como referência (benchmark) para a mensuração de spreads efetivos, pois fornece informações precisas sobre transações intradiárias, permitindo o cálculo direto dos custos de transação reais enfrentados pelos participantes do mercado. Os autores utilizam dados do TAQ como padrão-ouro para validar a eficácia de seu estimador de spread bid-ask, demonstrando que as estimativas baseadas em seu modelo apresentam alta correlação com os spreads efetivos calculados a partir dos dados de alta frequência do TAQ.

O método EDGE, desenvolvido por Ardia, Guidotti e Kroencke (2024), surge como uma proposta robusta para estimar o spread bid-ask de maneira eficiente, utilizando preços diários de abertura, máxima, mínima e fechamento (OHLC). Este método aborda uma limitação crítica de estimadores anteriores, como os de Corwin e Schultz (2012) e Abdi e Ranaldo (2017): o viés introduzido pela suposição de preços observados continuamente, que não reflete a realidade de mercados com baixa frequência de negociações.

O EDGE parte de três premissas centrais, compartilhadas com outros métodos: (1) os retornos fundamentais não são autocorrelacionados; (2) os retornos fundamentais são independentes das flutuações causadas pelo spread bid-ask; e (3) as flutuações do spread não possuem média e são não correlacionadas. No entanto, ele se diferencia ao relaxar a suposição de que preços são continuamente observados. Em mercados reais, a quantidade de negociações por intervalo de tempo é finita, o que resulta em um viés de subestimação dos spreads, especialmente em ativos com baixa liquidez. O EDGE corrige essa limitação introduzindo termos analíticos que ajustam o viés decorrente da observação discreta de preços.

Matematicamente, o spread bid-ask estimado pelo EDGE é definido como:

$$S = f(O_t, H_t, L_t, C_t),$$ {#eq-estimador-EDGE} \equations{Estimador EDGE}

onde $S$ é o spread estimado, e a função $f$ combina as estatísticas derivadas dos preços OHLC. Em essência, o método utiliza a amplitude intradiária normalizada para capturar a dinâmica entre o preço eficiente e o spread bid-ask. A amplitude é calculada como:

$$A_t = \ln \frac{H_t}{L_t},$$ {#eq-amplitude-intradiaria-EDGE} \equations{Amplitude intradiária}

e o ajuste para a observação discreta de preços é dado por:

$$D_t = \ln \frac{C_t}{O_t},$$ {#eq-ajuste-observacao-discreta} \equations{Ajuste para observação discreta}

onde $A_t$ reflete a volatilidade e $D_t$ corrige o viés causado pela não observação contínua dos preços. O spread estimado é então ajustado por um termo de correção baseado na variação observada em múltiplos dias consecutivos, representado como:

$$S = \alpha \cdot A_t + \beta \cdot D_t,$$ \equations{Spread estimado para EDGE}

em que os coeficientes $\alpha$ e $\beta$ são calibrados para garantir que o estimador seja imparcial e apresente a menor variância possível. Esses coeficientes são derivados empiricamente, considerando simulações e validações em diferentes mercados.

De acordo com Ardia, Guidotti e Kroencke (2024), uma das características mais inovadoras do EDGE é a combinação otimizada de estimadores derivados de diferentes combinações de preços (como abertura e fechamento, máxima e mínima). Isso é feito para minimizar a variância de estimação, resultando em um estimador eficiente que se destaca tanto em cenários de spreads baixos quanto elevados. Segundo o artigo, enquanto estimadores como o de Corwin e Schultz (2012) são mais precisos para spreads pequenos, e o de Abdi e Ranaldo (2017) apresenta menor viés para spreads grandes, o EDGE combina o melhor desses cenários, garantindo estimativas com menor variância e viés uniforme.

Comparando com métodos anteriores, como o de Abdi e Ranaldo, o EDGE generaliza sua abordagem ao considerar informações adicionais de preços de abertura e fechamento. Enquanto o estimador de Abdi e Ranaldo utiliza médias de preços máximos, mínimos e de fechamento para isolar o componente de volatilidade do spread, o EDGE aproveita todas as informações de OHLC e introduz ajustes analíticos para corrigir observações discretas. Além disso, o EDGE não requer ajustes adicionais para períodos sem negociação, como finais de semana e feriados, assim como o estimador de Abdi e Ranaldo.

Sendo assim, o EDGE é uma contribuição relevante para a literatura de microestrutura de mercado, oferecendo uma ferramenta confiável e eficiente para a estimação de custos de transação. Ele não apenas melhora a precisão das estimativas em relação a métodos tradicionais, mas também amplia sua aplicabilidade a diversos contextos de mercado, como períodos históricos e mercados emergentes.

Os três estimadores discutidos – Corwin-Schultz (CS), Abdi-Ranaldo (AR) e EDGE – foram escolhidos para este estudo com base nos achados da Revisão Narrativa de Literatura (RSL), que identificou estes modelos como os mais relevantes e inovadores para a estimação do spread bid-ask no contexto de mercados emergentes. A RSL permitiu mapear a evolução das metodologias de estimação, desde abordagens mais tradicionais até as contribuições mais recentes, destacando estes três estimadores por sua relevância teórica, robustez metodológica e capacidade de oferecer insights em diferentes contextos de mercado. Além disso, suas características complementares permitem uma análise comparativa detalhada de suas performances no mercado brasileiro, que é classificado como emergente.

A aplicação dos métodos será realizada em três períodos distintos: pré-pandemia, durante a pandemia e no pós-pandemia. O período pré-pandemia é caracterizado por uma maior estabilidade econômica e condições de mercado mais previsíveis, oferecendo uma base para avaliar o desempenho dos estimadores em um cenário mais controlado. Durante a pandemia, o mercado foi marcado por alta volatilidade e incertezas, o que representa um contexto de maior desafio para os estimadores, especialmente em ativos menos líquidos. Por fim, o período pós-pandemia reflete um mercado em processo de readaptação, com uma recuperação gradual da liquidez e uma nova estabilidade, permitindo verificar a consistência dos métodos em cenários intermediários.

Com isso, este estudo busca avaliar como cada método se adapta às características específicas do mercado brasileiro e dos diferentes contextos temporais, contribuindo para a literatura de microestrutura ao explorar os pontos fortes e limitações de cada estimador em mercados emergentes e desafiadores.

## Cálculo do spread bid-ask

As três metodologias selecionadas foram: EDGE (Ardia, Guidotti e Kroencke, 2024), CS (Corwin e Schultz, 2012) e AR (Abdi e Ranaldo, 2017). O uso de uma janela móvel de 21 dias, representada pelo parâmetro *width* = 21, foi adotado para garantir consistência metodológica e facilitar a comparação com estudos anteriores, como os de Ardia, Guidotti e Kroencke (2024), que seguem o mesmo princípio. Essa configuração considera 21 dias como equivalente a aproximadamente um mês de negociações, com base na prática padrão em mercados financeiros, onde a média de dias úteis de negociação em um mês é de cerca de 21.

Além disso, no estudo de Ardia, Guidotti e Kroencke (2024), a aplicação do estimador é baseada em períodos de 21 dias úteis para representar um mês de negociações. Essa abordagem é consistente com os trabalhos de Corwin e Schultz (2012) e Abdi e Ranaldo (2017), que também utilizam essa mesma configuração temporal em suas análises e simulações. O objetivo é criar uma unidade temporal padronizada que permita avaliar variações no spread bid-ask de maneira comparável ao longo de diferentes períodos e contextos de negociação.

Essa escolha também facilita a análise do impacto de diferentes frequências de negociação, uma vez que uma janela de 21 dias captura tanto oscilações diárias quanto tendências mais amplas em cenários de alta e baixa liquidez. Portanto, a adoção desse parâmetro não só mantém a consistência com a literatura, mas também reflete práticas amplamente aceitas no campo de microestrutura de mercado, garantindo a robustez e a validade dos resultados obtidos no contexto do mercado brasileiro.

O cálculo foi realizado sobre as séries de preços de abertura, máxima, mínima, fechamento (OHLC) e volumes diários obtidos diretamente da B3. Os métodos foram aplicados sem modificações adicionais, seguindo rigorosamente os algoritmos descritos nos trabalhos originais, de forma a garantir a comparabilidade com os benchmarks teóricos.

## Métricas de avaliação

As estimativas obtidas pelas três abordagens foram comparadas com os valores de referência fornecidos pela Bloomberg, considerados o padrão-ouro para a estimativa do spread bid-ask. Para realizar essa análise, os dados da Bloomberg foram importados e integrados à base processada, permitindo a construção de comparativos entre as estimativas calculadas e os valores reportados. Essa integração foi necessária para garantir uma avaliação precisa da performance de cada método em relação a uma referência amplamente reconhecida no mercado financeiro. Foram utilizadas métricas estatísticas para medir a proximidade das estimativas com os valores de referência, como o erro quadrático médio (MSE), que avalia a magnitude do erro entre as estimativas, e o coeficiente de correlação de Pearson, que mede a força e a direção da associação entre os valores estimados e os da Bloomberg. Esses indicadores forneceram uma base objetiva para identificar as condições em que os estimadores apresentaram melhor ou pior desempenho, destacando suas capacidades e limitações em diferentes contextos de negociação.

### Métricas de erro

Para quantificar a precisão das estimativas geradas por cada abordagem em relação aos valores oficiais da Bloomberg, foram utilizadas as seguintes métricas de erro:

#### Erro Quadrático Médio (RMSE)

O RMSE é uma medida amplamente utilizada para avaliar a magnitude dos erros de estimação, calculada pela raiz quadrada da média dos quadrados das diferenças entre valores estimados e valores reais:

$$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$ {#eq-RMSE} \equations{Erro quadrático médio (EQM ou RMSE)}

onde $y_i$ representa o valor oficial do spread (Bloomberg) e $\hat{y}_i$ representa o valor estimado pela metodologia em análise. O RMSE atribui maior peso a erros maiores devido à operação de elevação ao quadrado, tornando-o particularmente sensível a outliers. Esta métrica foi escolhida como principal indicador de proximidade entre as estimativas e os valores reais, sendo que valores menores de RMSE indicam maior precisão do método.

#### Erro Absoluto Médio (MAE)

Como métrica complementar, foi utilizado o MAE, calculado pela média dos valores absolutos das diferenças entre valores estimados e valores reais:

$$MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$ {#eq-erro-absoluto-medio} \equations{Erro Absoluto Médio (MAE)}

O MAE atribui peso igual a todos os erros, independentemente de sua magnitude, oferecendo uma perspectiva alternativa sobre a precisão das estimativas.

### Teste de similaridade estatística - Kolmogorov-Smirnov

Para avaliar a similaridade estatística entre as distribuições das estimativas e dos valores oficiais, foi aplicado o teste de Kolmogorov-Smirnov (KS). Este teste não paramétrico avalia a hipótese nula de que duas amostras provêm da mesma distribuição. A estatística D do teste KS é calculada como:

$$D = \sup_x |F_1(x) - F_2(x)∣$$ {#eq-estatistica-d-ks} \equations{Estatística D de Kolmogorov-Smirnov}

onde $F_1(x)$ e $F_2(x)$ são as funções de distribuição acumulada empíricas para as duas amostras sendo comparadas, e $\sup_x$ representa o supremo (máximo) das diferenças entre as duas distribuições. A interpretação dos resultados do teste KS é baseada no p-valor:

-   p-valor \< 0,05: Rejeita-se a hipótese nula, indicando diferença estatisticamente significativa entre as distribuições.
-   p-valor ≥ 0,05: Não se rejeita a hipótese nula, sugerindo que não há evidência estatística suficiente para afirmar que as distribuições são diferentes.

\newpage

# Resultados

O estimador EDGE tem sua construção baseada na combinação otimizada de diferentes estimadores, minimizando a variância da estimativa final. Essa abordagem faz com que o método seja eficaz tanto em cenários de spreads estreitos quanto amplos, além de se adaptar automaticamente a variações na volatilidade do mercado. Dessa forma, a abordagem EDGE se mostra particularmente superior nos períodos de alta volatilidade, nos quais outras abordagens apresentam desempenho inconsistente.

A seguir, são apresentadas as análises comparativas entre os diferentes estimadores, com o objetivo de avaliar suas performances no contexto do mercado acionário brasileiro e identificar qual metodologia oferece maior precisão na mensuração do spread bid-ask.

## Análise dos estimadores

<!-- Montando a tabela de estatísticas -->

```{r calculo das estatisticas EDGE AR e CS, echo=FALSE, message=FALSE, warning=FALSE}
# Calcular as estatísticas para cada grupo e método
stats_table <- company_spreads_df %>%
  group_by(Group) %>%
  summarise(
    Media_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    DesvPad_EDGE = sd(Spread_EDGE, na.rm = TRUE),
    Mediana_EDGE = median(Spread_EDGE, na.rm = TRUE),
    Maximo_EDGE = max(Spread_EDGE, na.rm = TRUE),
    Minimo_EDGE = min(Spread_EDGE, na.rm = TRUE),
    Media_CS = mean(Spread_CS, na.rm = TRUE),
    DesvPad_CS = sd(Spread_CS, na.rm = TRUE),
    Mediana_CS = median(Spread_CS, na.rm = TRUE),
    Maximo_CS = max(Spread_CS, na.rm = TRUE),
    Minimo_CS = min(Spread_CS, na.rm = TRUE),
    Media_AR = mean(Spread_AR, na.rm = TRUE),
    DesvPad_AR = sd(Spread_AR, na.rm = TRUE),
    Mediana_AR = median(Spread_AR, na.rm = TRUE),
    Maximo_AR = max(Spread_AR, na.rm = TRUE),
    Minimo_AR = min(Spread_AR, na.rm = TRUE)
  ) %>%
  ungroup()

# Atribuir os grupos na ordem desejada
stats_table$Group <- factor(stats_table$Group,
                            levels = c("High Volume (Top 30%)", 
                                       "Middle Volume (40%)",
                                       "Low Volume (Bottom 30%)"))

stats_table <- stats_table %>% arrange(Group)

# Dividir a stats_table em três tabelas separadas por método
stats_table_EDGE <- stats_table %>%
  select(Group, Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE)

stats_table_CS <- stats_table %>%
  select(Group, Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS)

stats_table_AR <- stats_table %>%
  select(Group, Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR)

# Criar a tabela para EDGE
tabela_EDGE <- stats_table_EDGE %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "EDGE",
    columns = c("Media_EDGE", "DesvPad_EDGE", "Mediana_EDGE", "Maximo_EDGE", "Minimo_EDGE")
  ) %>%
  cols_label(
    Media_EDGE = "Média",
    DesvPad_EDGE = "DesvPad",
    Mediana_EDGE = "Mediana",
    Maximo_EDGE = "Máximo",
    Minimo_EDGE = "Mínimo"
  ) %>%
  cols_width(
    c(Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE) ~ px(80)
  ) %>%
  gt::fmt_number(
    columns = c(Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE),
    decimals = 6
  )

# Criar a tabela para CS
tabela_CS <- stats_table_CS %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "CS",
    columns = c("Media_CS", "DesvPad_CS", "Mediana_CS", "Maximo_CS", "Minimo_CS")
  ) %>%
  cols_label(
    Media_CS = "Média",
    DesvPad_CS = "DesvPad",
    Mediana_CS = "Mediana",
    Maximo_CS = "Máximo",
    Minimo_CS = "Mínimo"
  ) %>%
  cols_width(
    c(Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS) ~ px(80)
  ) %>%
  gt::fmt_number(
    columns = c(Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS),
    decimals = 6
  )

# Criar a tabela para AR
tabela_AR <- stats_table_AR %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "AR",
    columns = c("Media_AR", "DesvPad_AR", "Mediana_AR", "Maximo_AR", "Minimo_AR")
  ) %>%
  cols_label(
    Media_AR = "Média",
    DesvPad_AR = "DesvPad",
    Mediana_AR = "Mediana",
    Maximo_AR = "Máximo",
    Minimo_AR = "Mínimo"
  ) %>%
  cols_width(
    c(Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR) ~ px(80)
  ) %>%
  gt::fmt_number(
    columns = c(Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR),
    decimals = 6
  )

```


```{r teste t para os 3 estimadores}
# Extrair os spreads EDGE para os grupos de alta e baixa liquidez
spreads_high_volume <- company_spreads_df %>%
  filter(Group == "High Volume (Top 30%)") %>%
  pull(Spread_EDGE)

spreads_low_volume <- company_spreads_df %>%
  filter(Group == "Low Volume (Bottom 30%)") %>%
  pull(Spread_EDGE)

# Realizar teste-t entre os grupos de alta e baixa liquidez
teste_liquidez <- t.test(spreads_low_volume, spreads_high_volume)

# Criar tabela com os resultados do teste-t
resultados_teste_t_liquidez <- tibble(
  Comparação = "Baixa Liquidez vs Alta Liquidez (EDGE)",
  Estatística_t = round(teste_liquidez$statistic, 4),
  Valor_p = format(teste_liquidez$p.value, scientific = TRUE),
  Diferença_média = round(teste_liquidez$estimate[1] - teste_liquidez$estimate[2], 6)
)

# Formatar a tabela usando gt
tabela_teste_t_liquidez <- resultados_teste_t_liquidez %>%
  gt() %>%
  cols_label(
    Comparação = "Comparação",
    Estatística_t = "Estatística t",
    Valor_p = "Valor-p",
    Diferença_média = "Diferença Média"
  ) %>%
  fmt_number(
    columns = c(Estatística_t, Diferença_média),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(
      color = "darkred",
      weight = "bold"
    ),
    locations = cells_body(
      columns = Valor_p,
      rows = Valor_p < 0.05
    )
  )

# Exibir a tabela
# tabela_teste_t_liquidez

### - TESTE T PARA O ESTIMADOR CS - ###

# Extrair os spreads CS para os grupos de alta e baixa liquidez
spreads_high_volume_CS <- company_spreads_df %>%
  filter(Group == "High Volume (Top 30%)") %>%
  pull(Spread_CS)

spreads_low_volume_CS <- company_spreads_df %>%
  filter(Group == "Low Volume (Bottom 30%)") %>%
  pull(Spread_CS)

# Realizar teste-t entre os grupos de alta e baixa liquidez para CS
teste_liquidez_CS <- t.test(spreads_low_volume_CS, spreads_high_volume_CS)

# Criar tabela com os resultados do teste-t para CS
resultados_teste_t_liquidez_CS <- tibble(
  Comparação = "Baixa Liquidez vs Alta Liquidez (CS)",
  Estatística_t = round(teste_liquidez_CS$statistic, 4),
  Valor_p = format(teste_liquidez_CS$p.value, scientific = TRUE),
  Diferença_média = round(teste_liquidez_CS$estimate[1] - teste_liquidez_CS$estimate[2], 6)
)

# Formatar a tabela usando gt
tabela_teste_t_liquidez_CS <- resultados_teste_t_liquidez_CS %>%
  gt() %>%
  cols_label(
    Comparação = "Comparação",
    Estatística_t = "Estatística t",
    Valor_p = "Valor-p",
    Diferença_média = "Diferença Média"
  ) %>%
  fmt_number(
    columns = c(Estatística_t, Diferença_média),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(
      color = "darkred",
      weight = "bold"
    ),
    locations = cells_body(
      columns = Valor_p,
      rows = Valor_p < 0.05
    )
  )

# Exibir a tabela
# tabela_teste_t_liquidez_CS

### - TESTE T PARA O ESTIMADOR AR - ###
# Extrair os spreads AR para os grupos de alta e baixa liquidez
spreads_high_volume_AR <- company_spreads_df %>%
  filter(Group == "High Volume (Top 30%)") %>%
  pull(Spread_AR)

spreads_low_volume_AR <- company_spreads_df %>%
  filter(Group == "Low Volume (Bottom 30%)") %>%
  pull(Spread_AR)

# Realizar teste-t entre os grupos de alta e baixa liquidez para AR
teste_liquidez_AR <- t.test(spreads_low_volume_AR, spreads_high_volume_AR)

# Criar tabela com os resultados do teste-t para AR
resultados_teste_t_liquidez_AR <- tibble(
  Comparação = "Baixa Liquidez vs Alta Liquidez (AR)",
  Estatística_t = round(teste_liquidez_AR$statistic, 4),
  Valor_p = format(teste_liquidez_AR$p.value, scientific = TRUE),
  Diferença_média = round(teste_liquidez_AR$estimate[1] - teste_liquidez_AR$estimate[2], 6)
)

# Formatar a tabela usando gt
tabela_teste_t_liquidez_AR <- resultados_teste_t_liquidez_AR %>%
  gt() %>%
  cols_label(
    Comparação = "Comparação",
    Estatística_t = "Estatística t",
    Valor_p = "Valor-p",
    Diferença_média = "Diferença Média"
  ) %>%
  fmt_number(
    columns = c(Estatística_t, Diferença_média),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(
      color = "darkred",
      weight = "bold"
    ),
    locations = cells_body(
      columns = Valor_p,
      rows = Valor_p < 0.05
    )
  )

# Exibir a tabela
# tabela_teste_t_liquidez_AR

```


Como visto na @tbl-estatsedge, com as estatística do EDGE, na @tbl-estatscs, com as estatísticas do CS, e na @tbl-estatsar, com as estatísticas do AR, ao analisar os resultados obtidos, observa-se que o estimador EDGE apresentou valores mínimos de spread bid-ask de $1,6×10^{−5}$ para ativos mais líquidos, $2,4×10^{−5}$ para ativos de liquidez intermediária e $1,8×10^{−5}$ para ativos menos líquidos. Esses valores representam a diferença percentual relativa entre os preços de compra e venda em relação ao preço médio do ativo. Em contraste, o estimador CS retornou valores iguais a zero para todos os grupos de ativos. É importante notar que, conforme o esperado, a média e a mediana do spread bid-ask são consistentemente mais altas para o grupo de menor liquidez (0,008973 e 0,007426, respectivamente) em comparação com os ativos mais líquidos (0,008079 e 0,006728) e os de liquidez intermediária (0,008099 e 0,006832), confirmando o padrão esperado de maior spread para ativos com menor liquidez. Esta tendência se mantém em todos os três estimadores analisados, sendo mais pronunciada no método AR, que apresentou os maiores valores médios entre os três métodos.

::: {#tbl-estatsedge}
```{r visualizacao da tabela EDGE}
#| tbl-pos: H
tabela_EDGE
```

Fonte: Elaborado pelo autor

Tabela indicando as principais estatísticas do método EDGE
:::


::: {#tbl-estatscs}
```{r visualizacao da tabela CS}
#| tbl-pos: H
tabela_CS
```

<br>

Fonte: Elaborado pelo autor

Tabela indicando as principais estatísticas do método CS
:::


::: {#tbl-estatsar}
```{r visualizacao da tabela AR}
#| tbl-pos: H
tabela_AR
```

Fonte: Elaborado pelo autor

Tabela indicando as principais estatísticas do método AR
:::

```{r}
# Combinar os resultados dos três testes em uma única tabela
resultados_consolidados <- bind_rows(
  resultados_teste_t_liquidez,
  resultados_teste_t_liquidez_CS,
  resultados_teste_t_liquidez_AR
)

# Formatar a tabela consolidada
tabela_consolidada_teste_t_media_liquidez <- resultados_consolidados %>%
  gt() %>%
  cols_label(
    Comparação = "Comparação",
    Estatística_t = "Estatística t",
    Valor_p = "Valor-p",
    Diferença_média = "Diferença Média"
  ) %>%
  fmt_number(
    columns = c(Estatística_t, Diferença_média),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(
      color = "darkred",
      weight = "bold"
    ),
    locations = cells_body(
      columns = Valor_p,
      rows = Valor_p < 0.05
    )
  )

# Exibir a tabela consolidada
# tabela_consolidada_teste_t_media_liquidez
```

A @tbl-teste-t-liquidez confirma estatisticamente a significância dessas diferenças entre as médias dos grupos de liquidez. Os resultados do teste t mostram p-valores extremamente baixos (p < 0,05) para todas as comparações entre ativos de baixa e alta liquidez nos três estimadores. As estatísticas t elevadas (23,08 para EDGE, 38,85 para CS e 42,18 para AR) indicam diferenças substanciais e estatisticamente significativas, com as maiores diferenças médias observadas no estimador AR (0,001955), seguido pelo EDGE (0,000894) e CS (0,000779). Esses valores demonstram que o AR é mais sensível às variações de liquidez, capturando de forma mais acentuada as diferenças nos custos de transação entre os grupos de ativos. Esses achados estão em consonância com o exposto por Ardia, Guidotti e Kroencke (2024), que investigaram o desempenho de diferentes estimadores de spread bid-ask.

::: {#tbl-teste-t-liquidez}
```{r visualizacao da tabela de teste t da liquidez}
#| tbl-pos: H
tabela_consolidada_teste_t_media_liquidez
```

Fonte: Elaborado pelo autor

Teste t para Diferença de Médias entre Medidas de Liquidez, comparando spreads de grupos de alta e baixa liquidez
:::


Segundo Ardia, Guidotti e Kroencke (2024), enquanto todos os estimadores avaliados são não viesados em cenários com alta frequência de negociações (por exemplo, 390 negociações por dia), suas performances divergem significativamente à medida que essa frequência diminui. Especificamente, o estimador CS apresenta um viés negativo acentuado em frequências menores, chegando a estimar spreads nulos em situações com menos de dez negociações diárias. Isso ocorre devido à forte dependência do CS na suposição de que os ativos são negociados continuamente, o que não é válido em mercados com baixa liquidez.

Por outro lado, o EDGE mantém estimativas não viesadas independentemente do número de negociações, graças a um termo de correção analítico que considera a negociação infrequente. Nossos resultados corroboram essa evidência, mostrando que o EDGE não retorna valores nulos mesmo em ativos com baixa frequência de negociação, ao contrário do CS. Dessa forma, o EDGE se apresenta como uma técnica mais robusta e apropriada para estimar o spread bid-ask em mercados com ativos menos líquidos.

Ao incluir o estimador de Abdi e Ranaldo (2017) (AR) na análise, conforme apresentado na tabela @tbl-estatsar, observa-se que o AR também fornece resultados significativos na estimativa do spread bid-ask no mercado brasileiro. O estimador AR exibiu valores mínimos de spread bid-ask de $0,0$ para todos os grupos de ativos analisados. Embora apresente valores mínimos iguais a zero, o AR tende a estimar spreads consistentemente maiores em comparação com o CS e o EDGE.

Os resultados mostram que o estimador AR possui médias de spread bid-ask de $0,010710$ para ativos mais líquidos, $0,010854$ para ativos de liquidez intermediária e $0,012665$ para ativos menos líquidos, superiores às médias observadas para o EDGE ($0,008079$, $0,008099$ e $0,008973$, respectivamente) e significativamente maiores que as do CS ($0,003897$, $0,004129$ e $0,004676$). Esse comportamento sugere que o AR captura de maneira mais abrangente os custos de transação, especialmente em mercados com menor liquidez, onde a diferença entre os estimadores se torna ainda mais pronunciada.

Abdi e Ranaldo (2017) destacam que seu estimador é particularmente robusto em condições de baixa liquidez, pois utiliza preços de fechamento, máxima e mínima para estimar o spread bid-ask, sem dependência excessiva da frequência de negociação. Essa característica é essencial no contexto do mercado brasileiro, onde muitos ativos apresentam negociações infrequentes.

Comparando os três estimadores, nota-se que o CS apresenta os menores valores médios em todos os grupos de liquidez, frequentemente retornando valores nulos (mínimo igual a zero) em todos os níveis de volume negociado. O EDGE, ao introduzir termos de correção para a observação discreta de preços, mantém estimativas positivas mesmo em ambientes de baixa liquidez, nunca retornando valores zero. O AR, por sua vez, embora também apresente valores mínimos iguais a zero, tende a estimar spreads consistentemente mais elevados em todos os níveis de liquidez, possivelmente refletindo de forma mais acurada os custos totais enfrentados pelos investidores em mercados emergentes.

Esses achados enfatizam a importância de selecionar metodologias adequadas ao perfil de liquidez dos ativos analisados. Enquanto o CS pode subestimar os spreads em mercados menos líquidos, o EDGE e o AR demonstram vantagens claras ao capturar gradações de liquidez, como evidenciado pelo aumento progressivo nas médias e medianas conforme diminui o volume de negociação dos ativos no mercado brasileiro. O fato de o AR estimar spreads sistematicamente maiores pode fornecer insights adicionais sobre a presença de custos de transação elevados e assimetrias informacionais que não são completamente capturadas pelos outros estimadores.

## Análise de período de volatilidade

<!-- Tratamento dos dados para os períodos específicos para cada metodologia-->

```{r}
# Filtrar company_spreads_df para incluir apenas o ano de 2020
company_spreads_df_2020 <- company_spreads_df %>%
  filter(year(Date) == 2020)

# Calcular as estatísticas para cada grupo e método com 4 casas decimais
stats_table_2020 <- company_spreads_df_2020 %>%
  group_by(Group) %>%
  summarise(
    Media_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    DesvPad_EDGE = sd(Spread_EDGE, na.rm = TRUE),
    Mediana_EDGE = median(Spread_EDGE, na.rm = TRUE),
    Maximo_EDGE = max(Spread_EDGE, na.rm = TRUE),
    Minimo_EDGE = min(Spread_EDGE, na.rm = TRUE),
    Media_CS = mean(Spread_CS, na.rm = TRUE),
    DesvPad_CS = sd(Spread_CS, na.rm = TRUE),
    Mediana_CS = median(Spread_CS, na.rm = TRUE),
    Maximo_CS = max(Spread_CS, na.rm = TRUE),
    Minimo_CS = min(Spread_CS, na.rm = TRUE),
    Media_AR = mean(Spread_AR, na.rm = TRUE),
    DesvPad_AR = sd(Spread_AR, na.rm = TRUE),
    Mediana_AR = median(Spread_AR, na.rm = TRUE),
    Maximo_AR = max(Spread_AR, na.rm = TRUE),
    Minimo_AR = min(Spread_AR, na.rm = TRUE)
  ) %>%
  ungroup()

# Atribuir os grupos na ordem desejada
stats_table_2020$Group <- factor(stats_table_2020$Group,
                            levels = c("Ativos mais líquidos",
                                       "Ativos menos líquidos",
                                       "Todos"))

stats_table_2020 <- stats_table_2020 %>% arrange(Group)

# Dividir a stats_table_2020 em duas tabelas separadas
stats_table_EDGE_2020 <- stats_table_2020 %>%
  select(Group, Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE)

stats_table_CS_2020 <- stats_table_2020 %>%
  select(Group, Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS)

stats_table_AR_2020 <- stats_table_2020 %>%
  select(Group, Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR)

# Criar a tabela para EDGE
tabela_EDGE_2020 <- stats_table_EDGE_2020 %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "EDGE",
    columns = c("Media_EDGE", "DesvPad_EDGE", "Mediana_EDGE", "Maximo_EDGE", "Minimo_EDGE")
  ) %>%
  cols_label(
    Media_EDGE = "Média",
    DesvPad_EDGE = "DesvPad",
    Mediana_EDGE = "Mediana",
    Maximo_EDGE = "Máximo",
    Minimo_EDGE = "Mínimo"
  ) %>%
  cols_width(
    c(Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE) ~ px(80)
  ) %>%
  fmt_number(
    columns = c(Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE),
    decimals = 6
  )

# Criar a tabela para CS
tabela_CS_2020 <- stats_table_CS_2020 %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "CS",
    columns = c("Media_CS", "DesvPad_CS", "Mediana_CS", "Maximo_CS", "Minimo_CS")
  ) %>%
  cols_label(
    Media_CS = "Média",
    DesvPad_CS = "DesvPad",
    Mediana_CS = "Mediana",
    Maximo_CS = "Máximo",
    Minimo_CS = "Mínimo"
  ) %>%
  cols_width(
    c(Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS) ~ px(80)
  ) %>%
  fmt_number(
    columns = c(Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS),
    decimals = 6
  )

# Criar a tabela para AR
tabela_AR_2020 <- stats_table_AR_2020 %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "AR",
    columns = c("Media_AR", "DesvPad_AR", "Mediana_AR", "Maximo_AR", "Minimo_AR")
  ) %>%
  cols_label(
    Media_AR = "Média",
    DesvPad_AR = "DesvPad",
    Mediana_AR = "Mediana",
    Maximo_AR = "Máximo",
    Minimo_AR = "Mínimo"
  ) %>%
  cols_width(
    c(Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR) ~ px(80)
  ) %>%
  fmt_number(
    columns = c(Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR),
    decimals = 6
  )

```

<!-- Tratamento dos dados para os períodos específicos -->

```{r, include = FALSE}
# Filtrar os dados para os períodos específicos
company_spreads_df_pre <- company_spreads_df %>%
  filter(year(Date) %in% c(2018, 2019))

company_spreads_df_2020 <- company_spreads_df %>%
  filter(year(Date) == 2020)

company_spreads_df_pos <- company_spreads_df %>%
  filter(year(Date) %in% c(2021, 2022))

# Calcular estatísticas para período pré-pandemia
stats_table_pre_CS <- company_spreads_df_pre %>%
  summarise(
    Media_CS = mean(Spread_CS, na.rm = TRUE),
    DesvPad_CS = sd(Spread_CS, na.rm = TRUE),
    Mediana_CS = median(Spread_CS, na.rm = TRUE),
    Maximo_CS = max(Spread_CS, na.rm = TRUE),
    Minimo_CS = min(Spread_CS, na.rm = TRUE)
  ) %>%
  mutate(Group = "Pré-pandemia")

stats_table_pre_EDGE <- company_spreads_df_pre %>%
  summarise(
    Media_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    DesvPad_EDGE = sd(Spread_EDGE, na.rm = TRUE),
    Mediana_EDGE = median(Spread_EDGE, na.rm = TRUE),
    Maximo_EDGE = max(Spread_EDGE, na.rm = TRUE),
    Minimo_EDGE = min(Spread_EDGE, na.rm = TRUE)
  ) %>%
  mutate(Group = "Pré-pandemia")

stats_table_pre_AR <- company_spreads_df_pre %>%
  summarise(
    Media_AR = mean(Spread_AR, na.rm = TRUE),
    DesvPad_AR = sd(Spread_AR, na.rm = TRUE),
    Mediana_AR = median(Spread_AR, na.rm = TRUE),
    Maximo_AR = max(Spread_AR, na.rm = TRUE),
    Minimo_AR = min(Spread_AR, na.rm = TRUE)
  ) %>%
  mutate(Group = "Pré-pandemia")

# Calcular estatísticas para período pré-pandemia
stats_table_dur_CS <- company_spreads_df_2020 %>%
  summarise(
    Media_CS = mean(Spread_CS, na.rm = TRUE),
    DesvPad_CS = sd(Spread_CS, na.rm = TRUE),
    Mediana_CS = median(Spread_CS, na.rm = TRUE),
    Maximo_CS = max(Spread_CS, na.rm = TRUE),
    Minimo_CS = min(Spread_CS, na.rm = TRUE)
  ) %>%
  mutate(Group = "Durante pandemia")

stats_table_dur_EDGE <- company_spreads_df_2020 %>%
  summarise(
    Media_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    DesvPad_EDGE = sd(Spread_EDGE, na.rm = TRUE),
    Mediana_EDGE = median(Spread_EDGE, na.rm = TRUE),
    Maximo_EDGE = max(Spread_EDGE, na.rm = TRUE),
    Minimo_EDGE = min(Spread_EDGE, na.rm = TRUE)
  ) %>%
  mutate(Group = "Durante pandemia")

stats_table_dur_AR <- company_spreads_df_2020 %>%
  summarise(
    Media_AR = mean(Spread_AR, na.rm = TRUE),
    DesvPad_AR = sd(Spread_AR, na.rm = TRUE),
    Mediana_AR = median(Spread_AR, na.rm = TRUE),
    Maximo_AR = max(Spread_AR, na.rm = TRUE),
    Minimo_AR = min(Spread_AR, na.rm = TRUE)
  ) %>%
  mutate(Group = "Durante pandemia")


# Calcular estatísticas para período pós-pandemia
stats_table_pos_CS <- company_spreads_df_pos %>%
  summarise(
    Media_CS = mean(Spread_CS, na.rm = TRUE),
    DesvPad_CS = sd(Spread_CS, na.rm = TRUE),
    Mediana_CS = median(Spread_CS, na.rm = TRUE),
    Maximo_CS = max(Spread_CS, na.rm = TRUE),
    Minimo_CS = min(Spread_CS, na.rm = TRUE)
  ) %>%
  mutate(Group = "Pós-pandemia")

stats_table_pos_EDGE <- company_spreads_df_pos %>%
  summarise(
    Media_EDGE = mean(Spread_EDGE, na.rm = TRUE),
    DesvPad_EDGE = sd(Spread_EDGE, na.rm = TRUE),
    Mediana_EDGE = median(Spread_EDGE, na.rm = TRUE),
    Maximo_EDGE = max(Spread_EDGE, na.rm = TRUE),
    Minimo_EDGE = min(Spread_EDGE, na.rm = TRUE)
  ) %>%
  mutate(Group = "Pós-pandemia")

stats_table_pos_AR <- company_spreads_df_pos %>%
  summarise(
    Media_AR = mean(Spread_AR, na.rm = TRUE),
    DesvPad_AR = sd(Spread_AR, na.rm = TRUE),
    Mediana_AR = median(Spread_AR, na.rm = TRUE),
    Maximo_AR = max(Spread_AR, na.rm = TRUE),
    Minimo_AR = min(Spread_AR, na.rm = TRUE)
  ) %>%
  mutate(Group = "Pós-pandemia")

# Combinar estatísticas com dados existentes da pandemia
stats_table_CS_completo <- bind_rows(
  stats_table_pre_CS,
  stats_table_dur_CS,
  stats_table_pos_CS
)

stats_table_EDGE_completo <- bind_rows(
  stats_table_pre_EDGE,
  stats_table_dur_EDGE,
  stats_table_pos_EDGE
)

stats_table_AR_completo <- bind_rows(
  stats_table_pre_AR,
  stats_table_dur_AR,
  stats_table_pos_AR
)

# Criar as tabelas expandidas
tabela_CS_completa <- stats_table_CS_completo %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "CS",
    columns = c("Media_CS", "DesvPad_CS", "Mediana_CS", "Maximo_CS", "Minimo_CS")
  ) %>%
  cols_label(
    Media_CS = "Média",
    DesvPad_CS = "DesvPad",
    Mediana_CS = "Mediana",
    Maximo_CS = "Máximo",
    Minimo_CS = "Mínimo"
  ) %>%
  cols_width(
    c(Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS) ~ px(80)
  ) %>%
  fmt_number(
    columns = c(Media_CS, DesvPad_CS, Mediana_CS, Maximo_CS, Minimo_CS),
    decimals = 6
  )

tabela_EDGE_completa <- stats_table_EDGE_completo %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "EDGE",
    columns = c("Media_EDGE", "DesvPad_EDGE", "Mediana_EDGE", "Maximo_EDGE", "Minimo_EDGE")
  ) %>%
  cols_label(
    Media_EDGE = "Média",
    DesvPad_EDGE = "DesvPad",
    Mediana_EDGE = "Mediana",
    Maximo_EDGE = "Máximo",
    Minimo_EDGE = "Mínimo"
  ) %>%
  cols_width(
    c(Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE) ~ px(80)
  ) %>%
  fmt_number(
    columns = c(Media_EDGE, DesvPad_EDGE, Mediana_EDGE, Maximo_EDGE, Minimo_EDGE),
    decimals = 6
  )

tabela_AR_completa <- stats_table_AR_completo %>%
  gt(rowname_col = "Group") %>%
  tab_spanner(
    label = "AR",
    columns = c("Media_AR", "DesvPad_AR", "Mediana_AR", "Maximo_AR", "Minimo_AR")
  ) %>%
  cols_label(
    Media_AR = "Média",
    DesvPad_AR = "DesvPad",
    Mediana_AR = "Mediana",
    Maximo_AR = "Máximo",
    Minimo_AR = "Mínimo"
  ) %>%
  cols_width(
    c(Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR) ~ px(80)
  ) %>%
  fmt_number(
    columns = c(Media_AR, DesvPad_AR, Mediana_AR, Maximo_AR, Minimo_AR),
    decimals = 6
  )
```

<!-- Cálculo do teste-T para comparação de médias entre os grupos de CS-->

```{r teste-t-cs, include = FALSE}
# Teste t para comparação de médias entre os grupos de CS

# Filtrar os dados para os três períodos específicos
spreads_pre <- company_spreads_pre$Spread_CS
spreads_pandemia <- company_spreads_dur$Spread_CS
spreads_pos <- company_spreads_pos$Spread_CS

# Realizar teste-t entre pré-pandemia e pandemia
teste_pre_pandemia <- t.test(spreads_pre, spreads_pandemia)

# Realizar teste-t entre pandemia e pós-pandemia
teste_pandemia_pos <- t.test(spreads_pandemia, spreads_pos)

# Realizar teste-t entre pré-pandemia e pós-pandemia
teste_pre_pos <- t.test(spreads_pre, spreads_pos)

# Criar tabela com os resultados dos testes-t
resultados_teste_t_CS <- tibble(
  Comparação = c("Pré-pandemia vs Pandemia", "Pandemia vs Pós-pandemia", "Pré-pandemia vs Pós-pandemia"),
  Estatística_t = c(round(teste_pre_pandemia$statistic, 4), 
                    round(teste_pandemia_pos$statistic, 4), 
                    round(teste_pre_pos$statistic, 4)),
  Valor_p = c(format(teste_pre_pandemia$p.value, scientific = TRUE), 
              format(teste_pandemia_pos$p.value, scientific = TRUE), 
              format(teste_pre_pos$p.value, scientific = TRUE)),
  Diferença_média = c(round(teste_pre_pandemia$estimate[2] - teste_pre_pandemia$estimate[1], 6),
                      round(teste_pandemia_pos$estimate[1] - teste_pandemia_pos$estimate[2], 6),
                      round(teste_pre_pos$estimate[2] - teste_pre_pos$estimate[1], 6))
)

# Formatar a tabela usando gt
tabela_teste_t_CS <- resultados_teste_t_CS %>%
  gt() %>%
  cols_label(
    Comparação = "Comparação",
    Estatística_t = "Estatística t",
    Valor_p = "Valor-p",
    Diferença_média = "Diferença Média"
  ) %>%
  fmt_number(
    columns = c(Estatística_t, Diferença_média),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(
      color = "darkred",
      weight = "bold"
    ),
    locations = cells_body(
      columns = Valor_p,
      rows = Valor_p < 0.05
    )
  )


```

Para compreender melhor como os diferentes estimadores de spread bid-ask se comportam em condições de mercado distintas, realizamos uma análise comparativa entre três períodos: pré-pandemia (2018-2019), pandemia (2020) e pós-pandemia (2021-2022). Esta segmentação temporal permite avaliar o desempenho dos estimadores em cenários de normalidade relativa, extrema volatilidade e recuperação, respectivamente.

Os dados na @tbl-estatscs20 apresentam os resultados do estimador CS nos três períodos analisados. Este método consistentemente mostra os valores médios de spread bid-ask mais baixos em comparação com os outros estimadores. No período pré-pandemia, o spread médio foi de 0,003848, com desvio padrão de 0,002896. Durante a pandemia, observa-se um aumento significativo para 0,005374 (incremento de 39,7%), com desvio padrão de 0,004790, evidenciando tanto um aumento no spread quanto uma maior dispersão nas estimativas. No período pós-pandemia, os valores apresentaram uma redução para 0,004466 (diminuição de 16,9% em relação ao período da pandemia), indicando uma recuperação parcial das condições de mercado, porém ainda 16,1% acima dos níveis pré-pandemia.

<!-- Tabela de estatísticas do método CS para os três períodos -->

::: {#tbl-estatscs20}
```{r exibir periodos CS}
tabela_CS_completa
```

Fonte: Elaborado pelo autor

Tabela indicando as principais estatísticas do método CS para pré-pandemia, ano da pandemia (2020) e pós-pandemia
:::

Os resultados do teste t apresentados na @tbl-teste-t-cs20 confirmam que estas variações são estatisticamente significativas, com p-valores muito baixos (p \< 0,05) para todas as comparações entre períodos. A diferença média entre os períodos pré-pandemia e pandemia (0,001535) é maior que a diferença entre os períodos pós-pandemia e pré-pandemia (0,000632), corroborando a constatação de que, embora tenha havido recuperação após o período crítico, os spreads não retornaram completamente aos níveis anteriores à crise. O teste estatístico valida, portanto, a hipótese de que a pandemia causou um impacto substantivo e mensurável nos custos de transação do mercado brasileiro, conforme capturado pelo estimador CS.

<!-- Tabela de teste-t para CS, comparando as médias entre os períodos-->

::: {#tbl-teste-t-cs20}
```{r exibir teste-t CS}
# Exibir a tabela de teste t para CS
tabela_teste_t_CS
```

Fonte: Elaborado pelo autor

Tabela de teste estatístico T para comparação de médias entre os grupos de CS
:::

<!-- Cálculo do teste-T para comparação de médias entre os grupos de EDGE-->

```{r teste-t EDGE}
# Teste t para comparação de médias entre os grupos de EDGE

# Filtrar os dados para os três períodos específicos
spreads_pre <- company_spreads_pre$Spread_EDGE
spreads_pandemia <- company_spreads_dur$Spread_EDGE
spreads_pos <- company_spreads_pos$Spread_EDGE

# Realizar teste-t entre pré-pandemia e pandemia
teste_pre_pandemia <- t.test(spreads_pre, spreads_pandemia)

# Realizar teste-t entre pandemia e pós-pandemia
teste_pandemia_pos <- t.test(spreads_pandemia, spreads_pos)

# Realizar teste-t entre pré-pandemia e pós-pandemia
teste_pre_pos <- t.test(spreads_pre, spreads_pos)

# Criar tabela com os resultados dos testes-t
resultados_teste_t_EDGE <- tibble(
  Comparação = c("Pré-pandemia vs Pandemia", "Pandemia vs Pós-pandemia", "Pré-pandemia vs Pós-pandemia"),
  Estatística_t = c(round(teste_pre_pandemia$statistic, 4), 
                    round(teste_pandemia_pos$statistic, 4), 
                    round(teste_pre_pos$statistic, 4)),
  Valor_p = c(format(teste_pre_pandemia$p.value, scientific = TRUE), 
              format(teste_pandemia_pos$p.value, scientific = TRUE), 
              format(teste_pre_pos$p.value, scientific = TRUE)),
  Diferença_média = c(round(teste_pre_pandemia$estimate[2] - teste_pre_pandemia$estimate[1], 6),
                      round(teste_pandemia_pos$estimate[1] - teste_pandemia_pos$estimate[2], 6),
                      round(teste_pre_pos$estimate[2] - teste_pre_pos$estimate[1], 6))
)

# Formatar a tabela usando gt
tabela_teste_t_EDGE <- resultados_teste_t_EDGE %>%
  gt() %>%
  cols_label(
    Comparação = "Comparação",
    Estatística_t = "Estatística t",
    Valor_p = "Valor-p",
    Diferença_média = "Diferença Média"
  ) %>%
  fmt_number(
    columns = c(Estatística_t, Diferença_média),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(
      color = "darkred",
      weight = "bold"
    ),
    locations = cells_body(
      columns = Valor_p,
      rows = Valor_p < 0.05
    )
  )

```

Já o estimador EDGE, na @tbl-estatsedge20, apresenta valores intermediários entre os três métodos analisados, porém com maior sensibilidade às condições de mercado. No período pré-pandemia, o spread médio foi de 0,007435, com desvio padrão de 0,004471. Durante a pandemia, o EDGE registrou um aumento expressivo para 0,012245 (incremento de 64,7%), com desvio padrão mais que duplicado (0,010944), demonstrando sua maior capacidade de capturar a volatilidade e a redução de liquidez desse período. No pós-pandemia, o método estimou um spread médio de 0,008234, representando uma redução de 32,8% em relação ao período crítico, mas ainda 10,7% acima dos níveis pré-pandemia, sugerindo uma normalização incompleta das condições de mercado.

<!-- Tabela de estatísticas do método EDGE para os três períodos -->

::: {#tbl-estatsedge20}
```{r exibir periodos EDGE}
tabela_EDGE_completa
```

Fonte: Elaborado pelo autor

Tabela indicando as principais estatísticas do método EDGE para pré-pandemia, ano da pandemia (2020) e pós-pandemia
:::

A @tbl-teste-t-edge20 corrobora estas observações, apresentando evidências estatísticas robustas da significância destas variações, com p-valores extremamente baixos em todas as comparações entre períodos. A estatística t para a comparação entre os períodos pré-pandemia e pandemia (-14,9366) é consideravelmente maior em valor absoluto do que a observada para o estimador CS (-9,2999). É notável também que, embora o teste t confirme que os valores do pós-pandemia permanecem significativamente diferentes dos níveis pré-pandemia (p = 0,00009601), a estatística t é substancialmente menor (-3,9372), sugerindo que o mercado caminha para uma normalização, ainda que incompleta.

<!-- Tabela de teste-t para EDGE, comparando as médias entre os períodos-->

::: {#tbl-teste-t-edge20}
```{r exibir teste-t EDGE}
# Exibir a tabela de teste t para EDGE
tabela_teste_t_EDGE
```

Fonte: Elaborado pelo autor

Tabela de teste estatístico T para comparação de médias entre os grupos de EDGE
:::

<!-- Cálculo do teste-T para comparação de médias entre os grupos de AR-->

```{r teste-t AR}
# Teste t para comparação de médias entre os grupos de AR

# Filtrar os dados para os três períodos específicos
spreads_pre <- company_spreads_pre$Spread_AR
spreads_pandemia <- company_spreads_dur$Spread_AR
spreads_pos <- company_spreads_pos$Spread_AR

# Realizar teste-t entre pré-pandemia e pandemia
teste_pre_pandemia <- t.test(spreads_pre, spreads_pandemia)

# Realizar teste-t entre pandemia e pós-pandemia
teste_pandemia_pos <- t.test(spreads_pandemia, spreads_pos)

# Realizar teste-t entre pré-pandemia e pós-pandemia
teste_pre_pos <- t.test(spreads_pre, spreads_pos)

# Criar tabela com os resultados dos testes-t
resultados_teste_t_AR <- tibble(
  Comparação = c("Pré-pandemia vs Pandemia", "Pandemia vs Pós-pandemia", "Pré-pandemia vs Pós-pandemia"),
  Estatística_t = c(round(teste_pre_pandemia$statistic, 4), 
                    round(teste_pandemia_pos$statistic, 4), 
                    round(teste_pre_pos$statistic, 4)),
  Valor_p = c(format(teste_pre_pandemia$p.value, scientific = TRUE), 
              format(teste_pandemia_pos$p.value, scientific = TRUE), 
              format(teste_pre_pos$p.value, scientific = TRUE)),
  Diferença_média = c(round(teste_pre_pandemia$estimate[2] - teste_pre_pandemia$estimate[1], 6),
                      round(teste_pandemia_pos$estimate[1] - teste_pandemia_pos$estimate[2], 6),
                      round(teste_pre_pos$estimate[2] - teste_pre_pos$estimate[1], 6))
)

# Formatar a tabela usando gt
tabela_teste_t_AR <- resultados_teste_t_AR %>%
  gt() %>%
  cols_label(
    Comparação = "Comparação",
    Estatística_t = "Estatística t",
    Valor_p = "Valor-p",
    Diferença_média = "Diferença Média"
  ) %>%
  fmt_number(
    columns = c(Estatística_t, Diferença_média),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(
      color = "darkred",
      weight = "bold"
    ),
    locations = cells_body(
      columns = Valor_p,
      rows = Valor_p < 0.05
    )
  )

```

O estimador AR, na @tbl-estatsar20, consistentemente produziu as maiores estimativas de spread bid-ask nos três períodos analisados. No período pré-pandemia, o spread médio foi de 0,009799, com desvio padrão de 0,005731. Durante a pandemia, o AR registrou o maior valor médio entre todos os métodos, atingindo 0,016082 (aumento de 64,1%), com desvio padrão de 0,013405, refletindo sua alta sensibilidade às condições adversas de mercado.

::: {#tbl-estatsar20}
```{r exibir periodos AR}
tabela_AR_completa
```

Fonte: Elaborado pelo autor

Tabela indicando as principais estatísticas do método AR para pré-pandemia, ano da pandemia (2020) e pós-pandemia
:::

No período pós-pandemia, o spread médio reduziu para 0,011833 (queda de 26,4%), permanecendo 20,8% acima dos níveis pré-pandemia, o que sugere uma percepção mais conservadora deste método quanto à recuperação das condições de liquidez do mercado brasileiro. A @tbl-teste-t-ar20 valida estatisticamente estas variações, apresentando p-valores significativos em todas as comparações temporais realizadas. A estatística t para a comparação entre os períodos pré-pandemia e pandemia (-12,6516) demonstra uma sensibilidade similar à do EDGE (-14,9366), porém superior à do CS (-9,2999).

<!-- Tabela de teste-t para AR, comparando as médias entre os períodos-->

::: {#tbl-teste-t-ar20}
```{r exibir teste-t AR}
# Exibir a tabela de teste t para AR
tabela_teste_t_AR
```

Fonte: Elaborado pelo autor

Tabela de teste estatístico T para comparação de médias entre os grupos de AR
:::

A análise comparativa dos três estimadores ao longo dos diferentes períodos revela padrões consistentes e significativos sobre seu comportamento e sensibilidade às condições de mercado. Em primeiro lugar, observamos uma hierarquia clara nos valores estimados: o método CS sempre fornece as estimativas mais baixas, o AR as mais altas, e o EDGE ocupa uma posição intermediária. Esta ordenação se manteve inalterada nos três períodos analisados, sugerindo características estruturais inerentes a cada método.

Durante o período pré-pandemia, as diferenças entre os estimadores já eram evidentes, com o AR apresentando um spread médio 154,7% maior que o CS e o EDGE 93,2% maior. Estas diferenças substantivas indicam que, mesmo em condições normais de mercado, a escolha do estimador pode levar a conclusões significativamente distintas sobre os custos de transação no mercado brasileiro.

A pandemia de COVID-19 em 2020 proporcionou um experimento natural para avaliar a sensibilidade dos estimadores às condições extremas de mercado. Todos os métodos registraram aumentos expressivos em suas estimativas, refletindo o choque de liquidez e a alta volatilidade do período. Contudo, é notável que o EDGE e o AR demonstraram incrementos proporcionalmente maiores (64,7% e 64,1%, respectivamente) em comparação ao CS (39,7%). Esta diferença na magnitude da resposta, confirmada pelos valores t mais elevados nas comparações pré-pandemia vs pandemia (-14,9366 para EDGE e -12,6516 para AR contra -9,2999 para CS), sugere que o CS pode subestimar os custos de transação em períodos de estresse de mercado, enquanto o EDGE e o AR capturam de forma mais completa o aumento dos spreads nessas condições.

Igualmente reveladora foi a análise dos desvios padrão, que apresentaram aumentos substanciais durante a pandemia: 65,4% para o CS, 144,8% para o EDGE e 133,9% para o AR. O aumento mais pronunciado na dispersão das estimativas do EDGE e do AR indica maior sensibilidade destes métodos à heterogeneidade das condições de mercado entre diferentes ativos e momentos, corroborando os resultados dos testes estatísticos que mostraram diferenças médias mais expressivas para estes estimadores.

No período pós-pandemia, todos os estimadores registraram reduções significativas em comparação ao auge da crise, sinalizando a gradual normalização das condições de mercado. No entanto, nenhum retornou completamente aos níveis pré-pandemia, sugerindo efeitos persistentes na liquidez e nos custos de transação. A magnitude da recuperação variou entre os métodos, com o EDGE mostrando a maior reversão (32,8% de redução), seguido pelo AR (26,4%) e pelo CS (16,9%).

Esta análise temporal reforça as conclusões anteriores sobre as características de cada estimador. O CS, com suas premissas de negociação contínua, parece menos sensível às variações nas condições de mercado, o que pode ser vantajoso para análises de longo prazo, mas problemático para capturar choques de liquidez. O EDGE, com seu termo de correção para negociações infrequentes, demonstra maior adaptabilidade a diferentes contextos, enquanto o AR consistentemente produz estimativas mais conservadoras dos custos de transação.

Os resultados sugerem que a escolha do estimador de spread bid-ask deve considerar não apenas o contexto geral do mercado, mas também os objetivos específicos da análise. Para avaliações em períodos de estresse ou em mercados com liquidez heterogênea, como o brasileiro, os estimadores EDGE e AR oferecem maior sensibilidade às variações nas condições de mercado, como demonstrado pelas diferenças médias mais expressivas e estatísticas t de maior magnitude. Em contrapartida, o CS pode ser adequado para análises comparativas de longo prazo em mercados mais estáveis, onde sua menor variância pode ser uma vantagem.

```{r}
# Função para calcular o RMSE
calcular_rmse <- function(estimativas, referencia) {
  sqrt(mean((estimativas - referencia)^2, na.rm = TRUE))
}

# Função para calcular o MAE
calcular_mae <- function(estimativas, referencia) {
  mean(abs(estimativas - referencia), na.rm = TRUE)
}

# Função para realizar o teste KS e retornar resultados formatados
realizar_ks_teste <- function(estimativas, referencia) {
  # Filtrar NAs antes do teste KS, pois ele não os suporta
  valid_estimativas <- estimativas[!is.na(estimativas) & !is.na(referencia)]
  valid_referencia <- referencia[!is.na(estimativas) & !is.na(referencia)]

  if (length(valid_estimativas) < 2 || length(valid_referencia) < 2) {
    # Retornar NA se não houver dados suficientes para o teste
    return(data.frame(
      D_estatistica = NA,
      p_valor = NA,
      resultado = "Dados insuficientes"
    ))
  }

  teste <- ks.test(valid_estimativas, valid_referencia)
  return(data.frame(
    D_estatistica = teste$statistic,
    p_valor = teste$p.value,
    resultado = ifelse(teste$p.value < 0.05, "Distribuições diferentes", "Distribuições similares")
  ))
}

# Aplicação das métricas para cada metodologia
resultados_erro <- data.frame(
  Metodologia = c("Corwin-Schultz", "Abdi-Ranaldo", "EDGE"),
  RMSE = c(
    calcular_rmse(company_spreads_df$Spread_CS, company_spreads_df$Spread_Bloomberg),
    calcular_rmse(company_spreads_df$Spread_AR, company_spreads_df$Spread_Bloomberg),
    calcular_rmse(company_spreads_df$Spread_EDGE, company_spreads_df$Spread_Bloomberg)
  ),
  MAE = c(
    calcular_mae(company_spreads_df$Spread_CS, company_spreads_df$Spread_Bloomberg),
    calcular_mae(company_spreads_df$Spread_AR, company_spreads_df$Spread_Bloomberg),
    calcular_mae(company_spreads_df$Spread_EDGE, company_spreads_df$Spread_Bloomberg)
  )
)

# -- Cálculo para Painel A: Por Grupo de Liquidez
resultados_erro_panel_A <- company_spreads_df %>%
  filter(!is.na(Spread_Bloomberg)) %>% # Remover NAs da referência antes de agrupar
  group_by(Group) %>%
  summarise(
    RMSE_CS = calcular_rmse(Spread_CS, Spread_Bloomberg),
    MAE_CS = calcular_mae(Spread_CS, Spread_Bloomberg),
    RMSE_AR = calcular_rmse(Spread_AR, Spread_Bloomberg),
    MAE_AR = calcular_mae(Spread_AR, Spread_Bloomberg),
    RMSE_EDGE = calcular_rmse(Spread_EDGE, Spread_Bloomberg),
    MAE_EDGE = calcular_mae(Spread_EDGE, Spread_Bloomberg),
    .groups = 'drop'
  ) %>%
  pivot_longer(
    cols = -Group,
    names_to = c(".value", "Metodologia"),
    names_pattern = "(RMSE|MAE)_(CS|AR|EDGE)"
  ) %>%
  mutate(Metodologia = case_when(
      Metodologia == "CS" ~ "Corwin-Schultz",
      Metodologia == "AR" ~ "Abdi-Ranaldo",
      Metodologia == "EDGE" ~ "EDGE",
      TRUE ~ Metodologia # Manter outros casos, se houver
  )) %>%
  # Assegurar a ordem correta dos fatores para Group
  mutate(Group = factor(Group, levels = c("High Volume (Top 30%)", "Middle Volume (40%)", "Low Volume (Bottom 30%)"))) %>%
  arrange(Group, Metodologia) %>%
  select(Metodologia, Group, RMSE, MAE) # Reordenar colunas

# -- Cálculo para Painel B: Por Período
calculate_period_errors <- function(df, period_name) {
  df %>%
    filter(!is.na(Spread_Bloomberg)) %>% # Remover NAs da referência
    summarise(
      RMSE_CS = calcular_rmse(Spread_CS, Spread_Bloomberg),
      MAE_CS = calcular_mae(Spread_CS, Spread_Bloomberg),
      RMSE_AR = calcular_rmse(Spread_AR, Spread_Bloomberg),
      MAE_AR = calcular_mae(Spread_AR, Spread_Bloomberg),
      RMSE_EDGE = calcular_rmse(Spread_EDGE, Spread_Bloomberg),
      MAE_EDGE = calcular_mae(Spread_EDGE, Spread_Bloomberg),
      .groups = 'drop'
    ) %>%
    mutate(Periodo = period_name)
}

# Usar os dataframes corretos para cada período
# Assumindo que company_spreads_df_pre, company_spreads_df_2020, company_spreads_df_pos existem
resultados_erro_panel_B <- bind_rows(
  calculate_period_errors(company_spreads_df_pre, "Pré-pandemia"),
  calculate_period_errors(company_spreads_df_2020, "Pandemia"), # Usando df_2020 para o período da pandemia
  calculate_period_errors(company_spreads_df_pos, "Pós-pandemia")
) %>%
  pivot_longer(
    cols = -Periodo,
    names_to = c(".value", "Metodologia"),
    names_pattern = "(RMSE|MAE)_(CS|AR|EDGE)"
  ) %>%
   mutate(Metodologia = case_when(
      Metodologia == "CS" ~ "Corwin-Schultz",
      Metodologia == "AR" ~ "Abdi-Ranaldo",
      Metodologia == "EDGE" ~ "EDGE",
      TRUE ~ Metodologia # Manter outros casos
  )) %>%
  # Assegurar a ordem correta dos fatores para Periodo
  mutate(Periodo = factor(Periodo, levels = c("Pré-pandemia", "Pandemia", "Pós-pandemia"))) %>%
  arrange(Periodo, Metodologia) %>%
  select(Metodologia, Periodo, RMSE, MAE) # Reordenar colunas


# -- Cálculo para Teste KS
# (O cálculo do KS permanece o mesmo, mas aplicamos a função atualizada)
ks_metodo1 <- realizar_ks_teste(company_spreads_df$Spread_CS, company_spreads_df$Spread_Bloomberg)
ks_metodo2 <- realizar_ks_teste(company_spreads_df$Spread_AR, company_spreads_df$Spread_Bloomberg)
ks_metodo3 <- realizar_ks_teste(company_spreads_df$Spread_EDGE, company_spreads_df$Spread_Bloomberg)

resultados_ks <- bind_rows(
  mutate(ks_metodo1, Metodologia = "Corwin-Schultz"),
  mutate(ks_metodo2, Metodologia = "Abdi-Ranaldo"),
  mutate(ks_metodo3, Metodologia = "EDGE")
) %>%
 select(Metodologia, D_estatistica, p_valor, resultado) # Reordenar colunas

```

## Análise comparativa com dados de referência da Bloomberg

Para avaliar a eficácia dos estimadores estudados em relação a uma referência de mercado amplamente reconhecida, realizou-se uma análise comparativa entre os spreads bid-ask estimados pelos métodos EDGE, CS e AR e os valores reportados pela Bloomberg. Esta comparação é fundamental para determinar qual metodologia oferece estimativas mais precisas no contexto específico do mercado brasileiro.

### Teste de similaridade estatística

O teste de Kolmogorov-Smirnov (KS) foi aplicado para verificar se as distribuições dos spreads estimados pelos três métodos são estatisticamente similares à distribuição dos valores de referência da Bloomberg. Este teste não paramétrico avalia a hipótese nula de que duas amostras provêm da mesma distribuição populacional.

::: {#tbl-tabelakolmogorov}
```{r}
# Formatar a tabela resultados_ks usando gt
resultados_ks_formatado <- resultados_ks %>%
  gt() %>%
  cols_label(
    Metodologia = "Metodologia",
    D_estatistica = "Estatística D",
    p_valor = "p-valor",
    resultado = "Resultado"
  ) %>%
  fmt_number(
    columns = c("D_estatistica", "p_valor"),
    decimals = 6
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  cols_width(
    Metodologia ~ px(150),
    D_estatistica ~ px(120),
    p_valor ~ px(120),
    resultado ~ px(180)
  ) %>%
  tab_options(
    table.width = pct(100),
    column_labels.background.color = "lightgray",
    table.border.top.width = px(3),
    table.border.bottom.width = px(3)
  )

# Exibir a tabela formatada
resultados_ks_formatado
```

Fonte: Elaborado pelo autor

Tabela indicando o resultado do teste de Kolmogorov-Smirnov para cada metodologia de estimativa de spread bid-ask
:::

Conforme a @tbl-tabelakolmogorov, os resultados do teste KS revelaram p-valores iguais a zero e estatísticas D próximas a 1 para todas as três metodologias, indicando uma rejeição contundente da hipótese nula. Isso evidencia que as distribuições dos spreads estimados por CS, AR e EDGE são estatisticamente diferentes da distribuição dos spreads de referência da Bloomberg. Estas diferenças não são meramente aleatórias, mas refletem divergências sistemáticas nas estimativas. Este resultado sugere que os três métodos provavelmente capturam diferentes aspectos dos spreads ou possuem vieses estruturais distintos em relação aos valores de referência. A rejeição da hipótese nula para todos os estimadores indica a complexidade inerente à mensuração do spread bid-ask em mercados emergentes, onde fatores específicos podem não ser adequadamente capturados pelos modelos desenvolvidos originalmente para mercados mais líquidos e eficientes.

### Métricas de erro

Para quantificar a precisão das estimativas em relação aos valores de referência, foram calculadas duas métricas de erro: o Erro Quadrático Médio (RMSE) e o Erro Absoluto Médio (MAE). Estas métricas permitem uma avaliação objetiva da magnitude das diferenças entre os valores estimados e os valores de referência. Os resultados das métricas de erro revelaram diferenças significativas entre as metodologias:

::: {#tbl-result-erro-paineis-A}
```{r}
resultados_erro_panel_A %>%
  gt(groupname_col = "Metodologia") %>% # Agrupar por Metodologia visualmente
  cols_label(
    Group = "Grupo de Liquidez",
    RMSE = "RMSE",
    MAE = "MAE"
  ) %>%
  fmt_number(
    columns = c(RMSE, MAE),
    decimals = 6
  ) %>%
   cols_width(
    c(RMSE, MAE) ~ px(130) # Ajuste o valor conforme necessário
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups() # Deixar nomes das metodologias em negrito
  ) %>%
  # Estilo para os cabeçalhos das colunas
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything()) # Deixar cabeçalhos em negrito
  ) %>%
  # Alinhar a primeira coluna (Período) à esquerda
  cols_align(
    align = "left",
    columns = Group
  ) %>%
  # Alinhar as colunas numéricas (RMSE, MAE) ao centro ou direita, se preferir
  cols_align(
    align = "center", # ou "right"
    columns = c(RMSE, MAE)
  ) %>%
  tab_options(
    table.width = pct(65),
    table.align = "center"
  )

```

Fonte: Elaborado pelo autor

Painel de métricas de erro RMSE e MAE por grupo de liquidez.
:::

::: {#tbl-result-erro-paineis-B}
```{r}
#| tbl-cap: "RMSE e MAE por Metodologia e Período"
#| tbl-cap-location: top

resultados_erro_panel_B %>%
  gt(groupname_col = "Metodologia") %>% # Agrupar por Metodologia visualmente
  cols_label(
    Periodo = "Período",
    RMSE = "RMSE",
    MAE = "MAE"
  ) %>%
  fmt_number(
    columns = c(RMSE, MAE),
    decimals = 6
  ) %>%
   cols_width(
    c(RMSE, MAE) ~ px(130) # Ajuste o valor conforme necessário
  ) %>%
   # Estilo para os nomes das metodologias (grupos de linhas)
   tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) %>%
  # Estilo para os cabeçalhos das colunas
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything()) # Deixar cabeçalhos em negrito
  ) %>%
  # Alinhar a primeira coluna (Período) à esquerda
  cols_align(
    align = "left",
    columns = Periodo
  ) %>%
  # Alinhar as colunas numéricas (RMSE, MAE) ao centro ou direita, se preferir
  cols_align(
    align = "center", # ou "right"
    columns = c(RMSE, MAE)
  ) %>%
  tab_options(
    table.width = pct(55), # Pode ser necessário ajustar a largura total da tabela
    table.align = "center" # Alinhamento geral da tabela na página
  )

```

Fonte: Elaborado pelo autor

Métricas de erro RMSE e MAE por período.
:::

Como visto nas @tbl-result-erro-paineis-A e @tbl-result-erro-paineis-B, o estimador EDGE consistentemente apresentou desempenho superior em ambos os painéis, com os menores valores de RMSE e MAE na maioria dos grupos de liquidez e períodos analisados. No Painel A (@tbl-result-erro-paineis-A), observa-se que o EDGE mantém vantagem de precisão especialmente no grupo de liquidez média ("Middle Volume"), onde apresentou RMSE de 1,012301 em comparação com 4,332984 e 4,333463 dos estimadores AR e CS, representando uma redução de aproximadamente 76,7% no erro quadrático médio.

Embora nos grupos de alta e baixa liquidez ("High Volume" e "Low Volume") os três estimadores tenham apresentado desempenho mais próximo, o EDGE ainda manteve ligeira vantagem. No grupo de maior liquidez, o EDGE registrou RMSE de 0,769317, comparado a 0,770545 do AR e 0,772264 do CS. Para ativos de menor liquidez, o EDGE demonstrou desempenho intermediário com RMSE de 1,112719, ligeiramente superior ao AR (1,111480), mas inferior ao CS (1,115113).

No Painel B (@tbl-result-erro-paineis-B), o EDGE demonstrou ser significativamente mais preciso no período pré-pandemia, com RMSE de 0,549047, valor aproximadamente 84,4% menor que os estimadores AR e CS, que apresentaram erros de 3,527887 e 3,528469, respectivamente. Durante o período da pandemia, o EDGE mostrou menor vantagem, mas ainda registrou valores competitivos (RMSE de 0,971952). No período pós-pandemia, os três estimadores apresentaram desempenho mais homogêneo, com o EDGE mantendo-se ligeiramente mais preciso que o CS.

Os valores de MAE reforçam este padrão, com o EDGE apresentando erros absolutos médios geralmente menores ou comparáveis aos outros estimadores. Notavelmente, no segmento de liquidez média, o EDGE apresentou MAE de 0,313644, consideravelmente inferior aos valores de 0,606266 e 0,612899 do AR e CS, respectivamente.

Estes resultados indicam que, embora nenhuma das metodologias reproduza perfeitamente a distribuição dos spreads Bloomberg (conforme indicado pelo teste KS), o estimador EDGE consegue gerar aproximações pontuais mais precisas, especialmente em períodos de menor volatilidade (pré-pandemia) e para ativos de liquidez intermediária. Esta superioridade está alinhada com as observações feitas nas análises temporais, onde o EDGE demonstrou maior adaptabilidade a diferentes contextos de mercado, graças ao seu termo de correção para negociações infrequentes, característica particularmente relevante para o mercado brasileiro.

### Interpretação integrada

A análise integrada dos resultados do teste KS e das métricas de erro permite uma compreensão mais completa do desempenho relativo dos estimadores no contexto do mercado brasileiro. Apesar de todas as metodologias produzirem distribuições estatisticamente diferentes dos valores de referência, o EDGE demonstrou capacidade superior para aproximar-se dos valores individuais, o que é evidenciado por seu menor RMSE e MAE. Essa característica é particularmente relevante em aplicações práticas, onde a precisão pontual das estimativas é frequentemente mais importante que a reprodução exata da distribuição completa.

A superioridade do EDGE pode ser atribuída à sua abordagem mais abrangente, que incorpora informações dos preços de abertura, máxima, mínima e fechamento, conforme descrito por Ardia, Guidotti e Kroencke (2024). Além disso, o EDGE inclui um termo de correção analítico para a negociação infrequente, característica comum em mercados menos líquidos como o brasileiro. Por outro lado, o desempenho similar dos estimadores CS e AR em termos de métricas de erro, apesar de suas diferentes formulações matemáticas, sugere que ambos podem estar sujeitos a limitações semelhantes quando aplicados ao mercado brasileiro. Isso pode estar relacionado a pressupostos subjacentes a esses modelos que não se aplicam plenamente ao contexto de mercados emergentes.

### Implicações para o mercado brasileiro

Os resultados desta análise comparativa têm implicações significativas para a escolha de metodologias de estimativa do spread bid-ask no mercado brasileiro:

O estimador EDGE emerge como a opção mais adequada para aplicações práticas, oferecendo estimativas com erro médio absoluto de aproximadamente 0,33 pontos base em relação aos valores de referência da Bloomberg. O fato de todas as metodologias produzirem distribuições estatisticamente diferentes da Bloomberg sugere que fatores específicos do mercado brasileiro, como a concentração de liquidez em determinados ativos e períodos, podem não estar sendo adequadamente capturados pelos modelos existentes. Estes achados corroboram os achados de Ardia, Guidotti e Kroencke (2024) que sugere que o EDGE é mais robusto em cenários de baixa liquidez e mercados emergentes, como mencionado no referencial teórico.

Em suma, enquanto nenhuma das metodologias analisadas reproduz perfeitamente os valores de referência da Bloomberg, o estimador EDGE oferece uma alternativa mais precisa quando os dados de alta frequência não estão disponíveis. Esta conclusão é particularmente relevante para pesquisadores, investidores e reguladores interessados na microestrutura do mercado brasileiro e em seus custos de transação.

\newpage

# Conclusão

Este estudo teve como objetivo geral comparar, no mercado acionário brasileiro, estimativas de spread bid-ask obtidas pelas abordagens de Corwin & Schultz (2012), Abdi & Ranaldo (2017) e EDGE (Ardia, Guidotti & Kroencke, 2024), tendo como referência a cotação de spread divulgada pela Bloomberg. A pesquisa desenvolveu-se a partir do reconhecimento da importância fundamental do spread bid-ask como componente da microestrutura de mercado, representando a diferença entre os preços de compra (bid) e venda (ask) de um ativo, refletindo assim os custos de transação e a liquidez do mercado.

A amostra utilizada foi composta por 130 ações listadas na B3, selecionadas com base em critérios de liquidez, onde foram consideradas apenas ações com índice de liquidez superior a 0,1, calculado em uma janela de seis meses. As ações foram distribuídas entre diferentes segmentos de governança corporativa: 93 pertencentes ao Novo Mercado, 16 ao Nível 2, 17 ao Nível 1 e 4 ao segmento Tradicional.

Metodologicamente, o estudo aplicou os três estimadores selecionados aos dados de preços diários (abertura, máxima, mínima, fechamento) e volumes obtidos diretamente da B3, utilizando uma janela móvel de 21 dias para garantir consistência com estudos anteriores. As estimativas foram comparadas com valores de referência da Bloomberg através do teste de Kolmogorov-Smirnov e das métricas de erro RMSE e MAE.

Os resultados do teste de Kolmogorov-Smirnov indicaram que as distribuições dos spreads estimados por todos os três métodos são estatisticamente diferentes da distribuição dos valores da Bloomberg, o que sugere que nenhum dos estimadores reproduz perfeitamente a complexidade do spread bid-ask no mercado brasileiro. Esta constatação aponta para a existência de características específicas deste mercado emergente que podem não estar sendo adequadamente capturadas pelos modelos desenvolvidos originalmente para mercados mais líquidos e eficientes.

A pesquisa se baseou principalmente nos trabalhos seminais dos autores dos próprios estimadores: Corwin e Schultz (2012), que propuseram uma metodologia baseada em preços diários de máxima e mínima; Abdi e Ranaldo (2017), que expandiram essa abordagem incluindo preços de fechamento; e Ardia, Guidotti e Kroencke (2024), que desenvolveram o estimador EDGE incorporando informações adicionais dos preços de abertura.

Os principais resultados demonstraram que, embora nenhum dos estimadores reproduza perfeitamente a distribuição dos spreads Bloomberg (conforme indicado pelo teste KS), o estimador EDGE apresentou desempenho significativamente superior, com RMSE de 0,97 e MAE de 0,33, valores aproximadamente 65% menores que os dos estimadores CS e AR. Durante o período de alta volatilidade de 2020, todos os estimadores registraram aumento nas médias dos spreads, com EDGE e AR demonstrando maior sensibilidade às condições adversas de mercado.

Esta pesquisa contribui para a literatura ao fornecer evidências sobre a eficácia relativa de diferentes metodologias de estimação do spread bid-ask especificamente no contexto de um mercado emergente como o brasileiro. Para estudos futuros, os resultados oferecem uma base para o desenvolvimento de estimadores mais adaptados às especificidades dos mercados emergentes, que tipicamente apresentam menor liquidez e maior volatilidade. A identificação do EDGE como estimador mais preciso também fornece orientação metodológica para pesquisadores interessados em mensurar custos de transação no mercado brasileiro.

Entre as limitações do estudo, destaca-se que os modelos foram originalmente calibrados e testados em mercados desenvolvidos, com estruturas distintas do brasileiro. Os pressupostos subjacentes a esses modelos, como a hipótese de negociação contínua, podem não se aplicar adequadamente ao contexto brasileiro, especialmente em ativos com menor liquidez. Adicionalmente, particularidades estruturais do mercado brasileiro, como a dinâmica da formação de preços na B3 e a concentração de liquidez em determinados horários, podem não ser completamente capturadas pelos modelos analisados.

\newpage

```{r, include = FALSE}
# Instalar pacotes necessários, se ainda não tiver
if (!requireNamespace("knitr", quietly = TRUE)) install.packages("knitr")

# Criar uma matriz com os dados
dados_cronograma <- matrix(
  c("X", "X", "X", "", "", "", "", "", "", "", "", "", "",
    "", "", "X", "X", "", "", "", "", "", "", "", "", "",
    "", "", "", "", "X", "", "", "", "", "", "", "", "",
    "", "", "", "", "X", "", "", "", "", "", "", "", "", # LINHA 4
    "", "", "", "", "X", "", "", "", "", "", "", "", "",
    "", "", "", "", "", "X", "X", "X", "", "", "", "", "",
    "", "", "", "", "", "", "", "X", "", "", "", "", "",
    "", "", "", "", "", "", "", "", "X", "", "", "", "", # LINHA 8
    "", "", "", "", "", "", "", "", "X", "", "", "", "",
    "", "", "", "", "", "", "", "", "", "X", "X", "X", "",
    "", "", "", "", "", "", "", "", "", "", "", "", "X",
    "", "", "", "", "", "", "", "", "", "", "", "", "X"),
  nrow = 12, byrow = TRUE
)

# Definir os nomes das linhas e colunas
rownames(dados_cronograma) <- c(
  "Realização da Revisão Narrativa de Literatura",
  "Redação do Projeto de pesquisa",
  "Defesa do Projeto",
  "Ajustes do Projeto com base nos comentários da banca",
  "Coleta da base de dados",
  "Aplicação da metodologia",
  "Análise dos resultados",
  "Defesa da qualificação",
  "Ajustes da qualificação com base nos comentários da banca",
  "Redação da dissertação",
  "Defesa da dissertação",
  "Ajustes da dissertação com base nos comentários da banca"
)
colnames(dados_cronograma) <- c("abr/24", "mai/24", "jun/24", "jul/24", "ago/24", "set/24", "out/24", "nov/24", "dez/24", "jan/25", "fev/25", "mar/25", "abr/25")

# Exibir a tabela
library(knitr)
kable(dados_cronograma, format = "latex", booktabs = FALSE, linesep = "") %>%
  kable_styling(
    latex_options = c("scale_down", "hold_position"),
    position = "center"
  ) %>%
  row_spec(c(1,2,3,4,5,6,7,8,9,10,11), hline_after = TRUE)  # Adiciona linhas horizontais após as linhas 2, 4 e 6
```

# Referências

\setlength{\parindent}{0pt} ABDI, F.; RANALDO, A. A simple estimation of bid-ask spreads from daily close, high, and low prices. \textbf{The review of financial studies}, v. 30, n. 12, p. 4437–4480, 2017.

ARAÚJO, G. S.; BARBEDO, C. H. DA S.; VICENTE, J. V. M. The adverse selection cost component of the spread of Brazilian stocks. \textbf{Emerging markets review}, v. 21, p. 21–41, 2014.

ARDIA, D.; GUIDOTTI, E.; KROENCKE, T. A. Efficient estimation of bid-ask spreads from open, high, low, and close prices. \textbf{SSRN Electronic Journal}, 2023.

BURTON GORDON MALKIEL. \textbf{A random walk down Wall Street : the time- tested strategy for successful investing}. New York: W.W. Norton, 2007.

CATTIVELLI, L.; PIRINO, D. A SHARP model of bid–ask spread forecasts. \textbf{International journal of forecasting}, v. 35, n. 4, p. 1211–1225, 2019.

CHORDIA, T.; ROLL, R.; SUBRAHMANYAM, A. Commonality in liquidity. \textbf{Journal of financial economics}, v. 56, n. 1, p. 3–28, 2000.

CONROY, R. M.; HARRIS, R. S.; BENET, B. A. The effects of stock splits on bid- ask spreads. \textbf{The journal of finance}, v. 45, n. 4, p. 1285–1295, 1990.

CORREIA, L. F.; AMARAL, H. Determinantes da liquidez de mercado de ações negociadas. \textbf{Revista Brasileira de Economia}, v. 68, n. 1, p. 89-110, 2014.

CORWIN, S. A.; SCHULTZ, P. A simple way to estimate bid-ask spreads from daily high and low prices. \textbf{The journal of finance}, v. 67, n. 2, p. 719–760, 2012.

DE JONG, F.; RINDI, B. \textbf{The Microstructure of Financial Markets}. Cambridge: Cambridge University Press, 2009.

DEMSETZ, H. The cost of transacting. \textbf{The Quarterly Journal of Economics}, v. 82, n. 1, p. 33, 1968.

EASLEY, D.; O’HARA, M. Price, trade size, and information in securities markets. \textbf{Journal of financial economics}, v. 19, n. 1, p. 69–90, 1987.

FAMA, E. F. The behavior of stock-market prices. \textbf{The journal of business}, v. 38, n. 1, p. 34, 1965.

FAMA, E. F. Efficient capital markets: A review of theory and empirical work. \textbf{The journal of finance}, v. 25, n. 2, p. 383, 1970.

FERREIRA, E. et al. Impacto assimétrico do sentimento do investidor na volatilidade do mercado acionário brasileiro. \textbf{Revista Brasileira de Gestão de Negócios}, v. 23, n. 2, p. 34-52, 2021.

GEORGE, T. J.; KAUL, G.; NIMALENDRAN, M. Estimation of the Bid-ask Spreads and its Components: A New Approach. \textbf{Review of Financial Studies}, p. 623–656, 1991.

GLOSTEN, L. R.; MILGROM, P. R. Bid, ask and transaction prices in a specialist market with heterogeneously informed traders. \textbf{Journal of financial economics}, v. 14, n. 1, p. 71–100, 1985.

HARRIS, L. \textbf{Trading and Exchanges: Market Microstructure for Practitioners}. Oxford: Oxford University Press, 2003.

HENDERSHOTT, T.; JONES, C. M.; MENKVELD, A. J. Does algorithmic trading improve liquidity? \textbf{The journal of finance}, v. 66, n. 1, p. 1–33, 2011.

HOLDEN, C. W.; JACOBSEN, S. Liquidity measurement problems in fast, competitive markets: Expensive and cheap solutions: Liquidity measurement problems in fast, competitive markets. \textbf{The journal of finance}, v. 69, n. 4, p. 1747–1785, 2014.

HUANG, R. D.; STOLL, H. R. The components of the bid-ask spread: A general approach. \textbf{The review of financial studies}, v. 10, n. 4, p. 995–1034, 1997.

ICHIMURA, D.; VIDEIRA, R.; RIPAMONTI, A. Asymmetric information and daily stock prices in Brazil. \textbf{Estudios gerenciales}, p. 465–472, 2020.

JENSEN, M. C. Some anomalous evidence regarding market efficiency. \textbf{Journal of Financial Economics}, v. 6, n. 2-3, p. 95–101, jun. 1978.

OLIVEIRA, R. \textbf{Como o fator de iliquidez afeta o retorno das ações brasileiras: Estudo Empírico}. São Paulo: Insper, 2018.

PEAT, M. Market data resources for researchers: The SIRCA data repository. \textbf{The Australian economic review}, v. 42, n. 4, p. 490–495, 2009.

PINTO, P. \textbf{Análise dos principais componentes do bid-ask spread de opções sobre ações no mercado brasileiro}. São Paulo: Insper, 2018.

RIPAMONTI, A. Corwin-Schultz bid-ask spread estimator in the Brazilian stock market. \textbf{Brazilian Administration Review}, v. 13, n. 1, p. 76–97, 2016.

ROLL, R. A simple implicit measure of the effective bid-ask spread in an efficient market. \textbf{The journal of finance}, v. 39, n. 4, p. 1127, 1984.

RYAN, Jeffrey; ULRICH, Joshua. Quantmod: Quantitative Financial Modelling Framework. Disponível em: https://github.com/joshuaulrich/quantmod. Acesso em: 24 nov. 2024.

STOIKOV, S. The micro-price: a high-frequency estimator of future prices. \textbf{Quantitative finance}, v. 18, n. 12, p. 1959–1966, 2018.

STOLL, H. R. Inferring the components of the bid-ask spread: Theory and empirical tests. \textbf{The journal of finance}, v. 44, n. 1, p. 115–134, 1989.

TOLEDO, R. \textbf{Determinantes da remuneração do spread de certificados de recebíveis do agronegócio no mercado brasileiro}. São Paulo: Fundação Getúlio Vargas, 2016.